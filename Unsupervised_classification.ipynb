{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu_3JH7FEH_W"
      },
      "source": [
        "# TP5 Catégorisez automatiquement des questions\n",
        "\n",
        "In this notebook we extract data from stackoverflow questions and perform an unsupervised text classification.\n",
        "\n",
        "The data can be originally found at: https://data.stackexchange.com/stackoverflow/query/new\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLuFT8xjKop5"
      },
      "source": [
        "# Download data: 100k posts containining Title, tags and text and score higher that 20\n",
        "\n",
        "We create an SQL program that samples 50K random posts without repetition. To achieve efficiency if we wish to sample 50k more posts, we shall sample independently from the previous 50k sample such that the merge of the samplings must be filtered for duplicates.  Here we use a dataset merge of 2 samplings with score greater than 20, as discussed in the data analisys notebook.\n",
        "\n",
        "The SQL script can be found in the following link:\n",
        "https://docs.google.com/document/d/1ywL1rGiYKzoftbgdNP-SPX-A250kaL1SxWRLeJsvk1A/edit?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R9P-4YUL836"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnvkeDV1K1Wt",
        "outputId": "4d1ea3cf-c90f-4a89-cb51-aedbf63b32d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1aGnT5OqAN7KmJoyEiWnFsnCELVun7s-s into ./data... Done.\n",
            "Unzipping...Done.\n",
            "Downloading 1-aKDsJDXPkhpzU0sAZ_4SC3gXKzGYuJV into ./data... Done.\n",
            "Unzipping...Done.\n",
            "Downloading 1WC60yk8Gen_eQocVPhnYNd3A5NJ5qZUf into ./data... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ],
      "source": [
        "# downlaod and unzip tags counts\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "files = ['1aGnT5OqAN7KmJoyEiWnFsnCELVun7s-s','1-aKDsJDXPkhpzU0sAZ_4SC3gXKzGYuJV', '1WC60yk8Gen_eQocVPhnYNd3A5NJ5qZUf']\n",
        "\n",
        "for file in files:\n",
        "  data_path = os.path.join('.','data')\n",
        "\n",
        "  gdd.download_file_from_google_drive(file_id=file,\n",
        "                                      dest_path=data_path,\n",
        "                                      unzip=True)\n",
        "  # remove .zip data\n",
        "  os.system('rm -rf data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCkwXZT6JBgl"
      },
      "source": [
        "# 1. Data pre-processing:\n",
        "\n",
        "First we need to analyse the data structure and decide which processing will be applied to the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMTwhrycJEkO"
      },
      "outputs": [],
      "source": [
        "df_part1 = pd.read_csv('QueryResults_part1.csv')\n",
        "df_part2 = pd.read_csv('QueryResults_part2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmJ3tNEW82L5"
      },
      "source": [
        "Since the two dataframes were gathered at random separately we must join without repeating data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAJMmhllO_5b"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([df_part1,df_part2]).drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37LLJfpG9EBe"
      },
      "source": [
        "As a sanity check, the joint dataset should have less than 100k questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1qM_O9T9AHQ",
        "outputId": "63022855-6217-4959-cd31-e2e9611434b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96387"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgBVCyScgnbr"
      },
      "source": [
        "Now we split our dataset into training and testing data. We can split training data further into another training set and an evaluation set.\n",
        "\n",
        "To avoid any bias in this sampling we shufle the dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCDK4i9Zg_mS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df, test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True,) # fix random state to reproduce results on other platforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsgrsWq0iIZw",
        "outputId": "83945f95-5547-4d06-9052-8a6f4c39f306"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77109"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "folK2qIgiMHJ",
        "outputId": "c915e7c5-a793-4f14-99f8-456a26869269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19278"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcpNQJgZJFLt"
      },
      "source": [
        "## 1.1 Tag pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pPVgk6J6MB9"
      },
      "source": [
        "Tags are written between less-than and greather-than signs on a single string.To work with individual tags we first have to process them using regex and create a list of tags that can be manipulated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wSDTG6qKUTfe",
        "outputId": "c4ac4ae7-6e89-48a1-96e6-e52bd2a05612"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Id                                               Body  \\\n",
              "67997  12019159  <p>I was going thru some single page website e...   \n",
              "76486  20580968  <p>Does anybody know why this error happens on...   \n",
              "29308   1000310  <p>I'm using guice for dependency injection wi...   \n",
              "83844  32325590  <p>I often get the following 500 server error ...   \n",
              "82803  30682575  <p>i got trouble, in a rails project（redmine2....   \n",
              "\n",
              "                                                   Title  \\\n",
              "67997  Infinite rotation animation using CSS and Java...   \n",
              "76486   Xcode error : Distill failed for unknown reasons   \n",
              "29308  What's aopalliance all about? And why is guice...   \n",
              "83844       Azure Web App: HTTP Error 500 on favicon.ico   \n",
              "82803  Unable to load the EventMachine C extension; T...   \n",
              "\n",
              "                                                    Tags         CreationDate  \\\n",
              "67997  [javascript, jquery, css, jquery-animate, css-...  2012-08-18 13:59:25   \n",
              "76486                 [ios, iphone, xcode, ios7, xcode5]  2013-12-14 07:51:40   \n",
              "29308                          [aop, guice, aopalliance]  2009-06-16 08:58:59   \n",
              "83844  [azure, iis, azure-web-app-service, azure-diag...  2015-09-01 07:10:23   \n",
              "82803     [ruby-on-rails, ruby, ruby-on-rails-3, bundle]  2015-06-06 11:58:18   \n",
              "\n",
              "       Score  \n",
              "67997     12  \n",
              "76486     51  \n",
              "29308     29  \n",
              "83844     12  \n",
              "82803     35  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bd8b7c6-9f64-4026-9fa3-18d58a1d9c4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>Title</th>\n",
              "      <th>Tags</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67997</th>\n",
              "      <td>12019159</td>\n",
              "      <td>&lt;p&gt;I was going thru some single page website e...</td>\n",
              "      <td>Infinite rotation animation using CSS and Java...</td>\n",
              "      <td>[javascript, jquery, css, jquery-animate, css-...</td>\n",
              "      <td>2012-08-18 13:59:25</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76486</th>\n",
              "      <td>20580968</td>\n",
              "      <td>&lt;p&gt;Does anybody know why this error happens on...</td>\n",
              "      <td>Xcode error : Distill failed for unknown reasons</td>\n",
              "      <td>[ios, iphone, xcode, ios7, xcode5]</td>\n",
              "      <td>2013-12-14 07:51:40</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29308</th>\n",
              "      <td>1000310</td>\n",
              "      <td>&lt;p&gt;I'm using guice for dependency injection wi...</td>\n",
              "      <td>What's aopalliance all about? And why is guice...</td>\n",
              "      <td>[aop, guice, aopalliance]</td>\n",
              "      <td>2009-06-16 08:58:59</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83844</th>\n",
              "      <td>32325590</td>\n",
              "      <td>&lt;p&gt;I often get the following 500 server error ...</td>\n",
              "      <td>Azure Web App: HTTP Error 500 on favicon.ico</td>\n",
              "      <td>[azure, iis, azure-web-app-service, azure-diag...</td>\n",
              "      <td>2015-09-01 07:10:23</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82803</th>\n",
              "      <td>30682575</td>\n",
              "      <td>&lt;p&gt;i got trouble, in a rails project（redmine2....</td>\n",
              "      <td>Unable to load the EventMachine C extension; T...</td>\n",
              "      <td>[ruby-on-rails, ruby, ruby-on-rails-3, bundle]</td>\n",
              "      <td>2015-06-06 11:58:18</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bd8b7c6-9f64-4026-9fa3-18d58a1d9c4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bd8b7c6-9f64-4026-9fa3-18d58a1d9c4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bd8b7c6-9f64-4026-9fa3-18d58a1d9c4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-544deb20-2a7f-41bd-b848-fec9e7e7b39a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-544deb20-2a7f-41bd-b848-fec9e7e7b39a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-544deb20-2a7f-41bd-b848-fec9e7e7b39a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# separate tags into a list of tags using a lambda function\n",
        "get_tags = lambda x: re.findall(\"\\<(.*?)\\>\", x)\n",
        "\n",
        "df['Tags'] = df['Tags'].apply(get_tags)\n",
        "test['Tags'] = test['Tags'].apply(get_tags)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyZk6i5UcFZK"
      },
      "source": [
        "#### Get Stackoverflow full tag data of top 50k most frequent tags\n",
        "\n",
        "As discussed in the exploratory analysis we can use stackoverflow top 50k tags of the whole dataset and obtain the mapping from token to tags as explained in the exploratory analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEOllY2_cQkS"
      },
      "outputs": [],
      "source": [
        "df_tags = pd.read_csv('TopTags.csv')\n",
        "df_tags.at[553, 'TagName'] = 'null'\n",
        "df_tags.at[1819, 'TagName'] = 'nan'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOpd0cDzcj8k"
      },
      "outputs": [],
      "source": [
        "# we will use the tag array to check for tag matches\n",
        "tags_array = (df_tags.TagName).to_numpy()[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAyF_MnswT5h"
      },
      "source": [
        "# 2. Title Pre-processing\n",
        "\n",
        "Here we process the title into a bow representation. This allows for a more in depth analysis of our data such that we can process it into features that can be better dealt by machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3qE1cXTpM06",
        "outputId": "93f86807-69c8-4a3e-ddf5-1b7359f17b70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Infinite rotation animation using CSS and Javascript',\n",
              " 'Xcode error : Distill failed for unknown reasons',\n",
              " \"What's aopalliance all about? And why is guice using it?\",\n",
              " 'Azure Web App: HTTP Error 500 on favicon.ico',\n",
              " 'Unable to load the EventMachine C extension; To use the pure-ruby reactor',\n",
              " 'Efficient implementation of faceted search in relational databases',\n",
              " 'Does calling a destructor explicitly destroy an object completely?',\n",
              " 'Calling Win32 API method from Java',\n",
              " 'Get a list of Solution/Project Files for VS Add-in or DXCore Plugin',\n",
              " 'Does Java Web Start require that the Java browser plug-in is enabled?']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Transform titles to list\n",
        "df.Title.to_list()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO7cHFtXw_Wi",
        "outputId": "cbc65b64-f92e-4805-e41d-3053f11211ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# download and import required packages\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "import nltk.stem as stemmer\n",
        "from nltk.stem.porter import *\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import MWETokenizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao1zfBAM0Zpk"
      },
      "outputs": [],
      "source": [
        "# instantiate stemmer that will be used along the processing pipeline\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5JrkGL981Wn"
      },
      "source": [
        "**Observation:** Since we use a out of the box tokenizer we can add our own rules to it. An example would be to add the token for C# (c sharp). Otherwise it would be removed by the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2YiTbDp8hfm"
      },
      "outputs": [],
      "source": [
        "# add exceptions to tokenizer\n",
        "tokenizer = nltk.tokenize.MWETokenizer()\n",
        "tokenizer.add_mwe(('c', '#'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofXAd1op8_K_"
      },
      "source": [
        "Here we define the preprocessing we will apply to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUhOR4RzkJAa"
      },
      "outputs": [],
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    # remove ponctuation but keep relevant data\n",
        "    initial_preprocess = lambda text : \"\".join([char for char in text if char not in '!\"$%&\\'()*,./:;<=>?@[\\\\]^_`{|}~']).lower()\n",
        "    tokens = tokenizer.tokenize(word_tokenize(initial_preprocess(text)))\n",
        "    for token in tokens:\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeh2lvpD9EGo"
      },
      "source": [
        "And we apply it to the train and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsymn7bPlqrk"
      },
      "outputs": [],
      "source": [
        "processed_titles = df.Title.map(preprocess)\n",
        "test_processed_titles = test.Title.map(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FRpmhH_9ISB"
      },
      "source": [
        "Below we observe that the result of the tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B27Ii8IQlwgE",
        "outputId": "6d5291ee-1836-4fe8-9d4d-b46906d417da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67997              [infinit, rotat, anim, css, javascript]\n",
              "76486        [xcode, error, distil, fail, unknown, reason]\n",
              "29308                                [what, aopalli, guic]\n",
              "83844       [azur, web, app, http, error, 500, faviconico]\n",
              "82803    [unabl, load, eventmachin, c, extens, use, pur...\n",
              "                               ...                        \n",
              "6265     [fastest, select, sqlcalcfoundrow, tabl, selec...\n",
              "54886        [set, dropdownlist, selecteditem, programmat]\n",
              "76820    [redirect, audio, creat, altern, sound, path, ...\n",
              "860                                     [differ, foo, foo]\n",
              "15795                                [cast, listt, effect]\n",
              "Name: Title, Length: 77109, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "processed_titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqxjzEWR9RaE"
      },
      "source": [
        "Now we generate a corpora dictionary using the tokenized sentences from the train dataset. We will print the first 10 words from the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjBDpqM_9eyd"
      },
      "outputs": [],
      "source": [
        "# Generate corpora dictionary\n",
        "title_dictionary = gensim.corpora.Dictionary(processed_titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIVLhrxr9wPa"
      },
      "source": [
        "Print the first 10 entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLEDUQUL9vUk",
        "outputId": "5fa36fde-e3cd-4594-eeca-4a56a16226f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 26743 entries on the corpora dict.\n",
            "First 10 entries:\n",
            "['anim', 'css', 'infinit', 'javascript', 'rotat', 'distil', 'error', 'fail', 'reason', 'unknown']\n"
          ]
        }
      ],
      "source": [
        "print('there are {} entries on the corpora dict.\\nFirst 10 entries:'.format(len(title_dictionary)))\n",
        "print(list(title_dictionary.values())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIX16qOF905e"
      },
      "source": [
        "To reduce the computational complexity we filter out words that appear less than a fixed number of times. The documentation of gives the following parameters:\n",
        "\n",
        "* no_below (int, optional) – Keep tokens which are contained in at least no_below documents.\n",
        "\n",
        "* no_above (float, optional) – Keep tokens which are contained in no more than no_above documents (fraction of total corpus size, not an absolute number).\n",
        "\n",
        "* keep_n (int, optional) – Keep only the first keep_n most frequent tokens.\n",
        "\n",
        "* keep_tokens (iterable of str) – Iterable of tokens that must stay in dictionary after filtering.\n",
        "\n",
        "We observe a great reduction in the number of the dictionary entries. This will greatly accelerate computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3EdK5K3Kj_9",
        "outputId": "9248a7e1-471e-45d1-8aa8-41fa03995c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After filtering there are 2431 entries on the corpora dict.\n",
            "First 10 entries:\n",
            "['anim', 'css', 'infinit', 'javascript', 'rotat', 'error', 'fail', 'reason', 'unknown', 'xcode']\n"
          ]
        }
      ],
      "source": [
        "title_dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=10000)\n",
        "print('After filtering there are {} entries on the corpora dict.\\nFirst 10 entries:'.format(len(title_dictionary)))\n",
        "print(list(title_dictionary.values())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRnWaP73AEAC"
      },
      "source": [
        "With the dictionary in hands we can now create a BoW representation of titles. We do this both for the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQNN3EuzNNu-"
      },
      "outputs": [],
      "source": [
        "# create bow of title filtered corpus\n",
        "title_bow_corpus = [title_dictionary.doc2bow(title) for title in processed_titles]\n",
        "test_title_bow_corpus = [title_dictionary.doc2bow(title) for title in test_processed_titles]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H2VZThkAv9y"
      },
      "source": [
        "We can now observe the result of the preprocessing on a string of text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTII9n9yMA4d"
      },
      "outputs": [],
      "source": [
        "# observe pre processing result on a sampling of a given dataset\n",
        "def sample_nlp_pipeline(sample_idx, dataframe, bow_corpus):\n",
        "  print('sample idx:', sample_idx)\n",
        "\n",
        "  print('sample tags:', dataframe.Tags.to_list()[sample_idx])\n",
        "  print('\\nprocessing pipeline: \\n')\n",
        "  print('sample title:', dataframe.Title.to_list()[sample_idx])\n",
        "  print('preprocessed title:', processed_titles[sample_idx])\n",
        "  print('bow_corpus of title:', bow_corpus[sample_idx])\n",
        "  print('\\nbag of words equivalence: ')\n",
        "  bow_doc_sample = bow_corpus[sample_idx]\n",
        "  for i in range(len(bow_doc_sample)):\n",
        "      print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_sample[i][0],\n",
        "                                                title_dictionary[bow_doc_sample[i][0]], bow_doc_sample[i][1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2yAANHtA9xc"
      },
      "source": [
        "Let's observe the result on a random question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7Z8YRqkQa1j",
        "outputId": "5e73a467-a3fd-46fe-d341-f73b470eadc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample idx: 15032\n",
            "sample tags: ['android', 'security', 'rsa', 'private-key']\n",
            "\n",
            "processing pipeline: \n",
            "\n",
            "sample title: Java: How can I generate PrivateKey from a string?\n",
            "preprocessed title: ['add', 'datamemb', 'collectiondatacontract', 'wcf']\n",
            "bow_corpus of title: [(34, 1), (66, 1), (266, 1)]\n",
            "\n",
            "bag of words equivalence: \n",
            "Word 34 (\"java\") appears 1 time.\n",
            "Word 66 (\"string\") appears 1 time.\n",
            "Word 266 (\"gener\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "# test preprocessing on a random question\n",
        "sample_nlp_pipeline(np.random.randint(len(df.Tags)), df, title_bow_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1eN4lyEaH1t"
      },
      "source": [
        "## 3.1 Token2tag\n",
        "\n",
        "To perform classification and evaluate we will use a dict of tokens to tag, as explained in the exploratory analysis notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QNV6mvAKbjIM",
        "outputId": "400687a2-bf7e-4396-8829-54f820d6e0ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id     TagName    Count\n",
              "0   3  javascript  2387264\n",
              "1  16      python  1968760\n",
              "2  17        java  1850627\n",
              "3   9          c#  1543059\n",
              "4   5         php  1438539"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21e49d48-a4fb-4d83-9fd9-0239e8b3fd35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>TagName</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>javascript</td>\n",
              "      <td>2387264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>python</td>\n",
              "      <td>1968760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>java</td>\n",
              "      <td>1850627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>c#</td>\n",
              "      <td>1543059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>php</td>\n",
              "      <td>1438539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21e49d48-a4fb-4d83-9fd9-0239e8b3fd35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21e49d48-a4fb-4d83-9fd9-0239e8b3fd35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21e49d48-a4fb-4d83-9fd9-0239e8b3fd35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b608699c-7d4e-4ac3-bdae-63bdf072a08b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b608699c-7d4e-4ac3-bdae-63bdf072a08b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b608699c-7d4e-4ac3-bdae-63bdf072a08b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df_tags.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT9y6MgSaHDR",
        "outputId": "5114cea0-0ce2-4651-ba71-c97e7d5b6892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total ammount of lost tags for tokenization: 0.29%\n"
          ]
        }
      ],
      "source": [
        "df_tags['tokenized'] = df_tags.TagName.apply(preprocess)\n",
        "\n",
        "# get array with tags\n",
        "tags_array = (df_tags.TagName).to_numpy()\n",
        "\n",
        "# get an array with tokenized tags\n",
        "tokenized_tags = df_tags.tokenized.to_numpy()\n",
        "\n",
        "# get an array with the tag count\n",
        "full_tag_count = (df_tags.Count).to_numpy()\n",
        "\n",
        "def select_first(token_list):\n",
        "  return [token_list[0]]\n",
        "\n",
        "# count number of total tags\n",
        "total = sum(full_tag_count)\n",
        "# initialize the\n",
        "n_lost = 0\n",
        "\n",
        "# we will capture index of divided or lost tags\n",
        "eliminated_tags = []\n",
        "divided_tags = []\n",
        "\n",
        "for idx, tag in enumerate(tags_array):\n",
        "  tokenized_tag = preprocess(tag)\n",
        "  # check if tag was mapped to zero\n",
        "  if len(tokenized_tag) == 0:\n",
        "      eliminated_tags.append(idx)\n",
        "      n_lost += full_tag_count[idx] / total * 100\n",
        "          #print(\"The tag '{}' ({:.2f}% of tags) was eliminated by tokenization\".format(full_tags_array[idx], full_tag_count[idx]/total*100))\n",
        "\n",
        "\n",
        "  # check if tags were divided\n",
        "  if len(tokenized_tag) > 1:\n",
        "      n_lost += full_tag_count[idx] / total * 100\n",
        "      divided_tags.append(idx)\n",
        "          #print(\"The tag '{}' ({:.2f}% of tags) was divided by tokenization into '{}'\".format(full_tags_array[idx], full_tag_count[idx]/total*100, tokenized_tag))\n",
        "\n",
        "print('\\nTotal ammount of lost tags for tokenization: {:.2f}%'.format(n_lost))\n",
        "\n",
        "\n",
        "df_tags.loc[divided_tags, 'tokenized'] = df_tags.loc[divided_tags, 'tokenized'].apply(select_first)\n",
        "\n",
        "token2tag_dict = {}\n",
        "for tag, token in zip(df_tags.TagName.to_numpy(), df_tags.tokenized.to_numpy()):\n",
        "  # token should be a list containing only one element\n",
        "  if len(token) == 0:\n",
        "    pass\n",
        "    #print('passed {} because the token is null'.format(tag))\n",
        "  elif token[0] in token2tag_dict.keys():\n",
        "    pass\n",
        "    #print('passed {} because the token has already been mapped'.format(tag))\n",
        "  else:#returning-a-view-versus-a-copy https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
        "    token2tag_dict[token[0]] = tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UYEl_5zCJaP"
      },
      "source": [
        "# 3. Unsupervised learning on titles\n",
        "\n",
        "In this section we will train a LDA model with the pre-processed titles. The resulting model will cluster the questions according to a number of topics.\n",
        "\n",
        "LDA stands for Latent Dirichlet Allocation. It is a probabilistic generative model allowing to explain sets of observations, by means of unobserved groups, them themselves defined by data similarities.\n",
        "\n",
        "In our context, since we already verified in the exploratory analysis that tags are present in the titles and text of questions, we can make the hypthesis that they end up making part of the topics.\n",
        "Furthermore, since the tags seem to appear on separate clusters of questions (ie. a python tag is not present in a C question), we also can expect that the topics encoding will also preserve this separation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ2jTkEwES0b"
      },
      "source": [
        "## 3.1 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5abauNcaNG4"
      },
      "source": [
        "### Question: How many topics should we use?\n",
        "\n",
        "This is an hyperparameter of the model. Tweaking it would offer ways to improve the results if we so desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DnSFnPU-z2g",
        "outputId": "18f1a51b-3721-4e29-adf3-ca9ac4811ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores available: 8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Get the number of available CPU cores\n",
        "num_cpus = os.cpu_count()\n",
        "print(\"Number of CPU cores available:\", num_cpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZVsJHG-LqRj"
      },
      "outputs": [],
      "source": [
        "# Fit LDA model using preprocessed titles\n",
        "\n",
        "title_lda_model = gensim.models.LdaMulticore(\n",
        "    title_bow_corpus,\n",
        "    num_topics=100,\n",
        "    id2word=title_dictionary,\n",
        "    passes=10,\n",
        "    workers=2,\n",
        "    eta='auto'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J5RVUOGikrE",
        "outputId": "2c84a45c-35bf-44e3-bfc8-cc6abfc41341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDdx8x6RwzWo"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model_file_path = \"/content/drive/MyDrive/Colab Notebooks/Lda models/title_lda_model\"\n",
        "title_lda_model.save(model_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plE2knm_27BX"
      },
      "source": [
        "The topics are a weighted combination of the processed tokens. Our unsupervised approach is now able to use this feature without any supervision to generate the predictions. We expect that the tags are present among the topic composition with high confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2cvxL-3OXL9",
        "outputId": "d3ca01d7-f3f2-4bcb-eada-a38e713d4d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.203*\"process\" + 0.154*\"messag\" + 0.093*\"respons\" + 0.083*\"5\" + 0.078*\"rout\" + 0.046*\"queue\" + 0.046*\"6\" + 0.042*\"clojur\" + 0.040*\"db\" + 0.030*\"asynchron\"\n",
            "Topic: 1 \n",
            "Words: 0.147*\"posit\" + 0.115*\"end\" + 0.102*\"height\" + 0.068*\"t-sql\" + 0.065*\"ssh\" + 0.053*\"absolut\" + 0.049*\"100\" + 0.040*\"reduc\" + 0.039*\"exe\" + 0.034*\"fatal\"\n",
            "Topic: 2 \n",
            "Words: 0.240*\"spring\" + 0.232*\"debug\" + 0.085*\"sqlite\" + 0.079*\"machin\" + 0.067*\"reason\" + 0.047*\"boot\" + 0.039*\"bean\" + 0.032*\"driver\" + 0.032*\"transit\" + 0.029*\"busi\"\n",
            "Topic: 3 \n",
            "Words: 0.268*\"number\" + 0.139*\"call\" + 0.135*\"detect\" + 0.093*\"2\" + 0.068*\"close\" + 0.068*\"calcul\" + 0.033*\"menu\" + 0.028*\"10\" + 0.026*\"convent\" + 0.025*\"admin\"\n",
            "Topic: 4 \n",
            "Words: 0.277*\"version\" + 0.124*\"ignor\" + 0.121*\"plugin\" + 0.108*\"avoid\" + 0.080*\"understand\" + 0.040*\"job\" + 0.036*\"clone\" + 0.026*\"restart\" + 0.025*\"white\" + 0.024*\"eclips\"\n",
            "Topic: 5 \n",
            "Words: 0.237*\"store\" + 0.162*\"output\" + 0.157*\"log\" + 0.074*\"state\" + 0.060*\"procedur\" + 0.060*\"remot\" + 0.048*\"wait\" + 0.045*\"continu\" + 0.033*\"storag\" + 0.021*\"suppress\"\n",
            "Topic: 6 \n",
            "Words: 0.245*\"test\" + 0.115*\"url\" + 0.113*\"xml\" + 0.080*\"instead\" + 0.079*\"unit\" + 0.079*\"r\" + 0.079*\"packag\" + 0.077*\"link\" + 0.074*\"includ\" + 0.012*\"head\"\n",
            "Topic: 7 \n",
            "Words: 0.258*\"order\" + 0.177*\"block\" + 0.137*\"know\" + 0.115*\"email\" + 0.078*\"subvers\" + 0.037*\"usernam\" + 0.034*\"makefil\" + 0.033*\"verifi\" + 0.027*\"margin\" + 0.020*\"-\"\n",
            "Topic: 8 \n",
            "Words: 0.229*\"build\" + 0.171*\"defin\" + 0.092*\"consol\" + 0.092*\"syntax\" + 0.083*\"encod\" + 0.043*\"error\" + 0.037*\"relationship\" + 0.037*\"monitor\" + 0.028*\"mous\" + 0.021*\"zend\"\n",
            "Topic: 9 \n",
            "Words: 0.279*\"differ\" + 0.256*\"function\" + 0.187*\"array\" + 0.096*\"c\" + 0.070*\"pass\" + 0.037*\"pointer\" + 0.013*\"c_#\" + 0.012*\"mark\" + 0.009*\"layer\" + 0.009*\"translat\"\n",
            "Topic: 10 \n",
            "Words: 0.247*\"servic\" + 0.099*\"allow\" + 0.079*\"2008\" + 0.068*\"host\" + 0.066*\"day\" + 0.060*\"js\" + 0.057*\"web\" + 0.057*\"navig\" + 0.052*\"product\" + 0.043*\"boolean\"\n",
            "Topic: 11 \n",
            "Words: 0.301*\"multipl\" + 0.223*\"select\" + 0.117*\"path\" + 0.090*\"statement\" + 0.052*\"panda\" + 0.048*\"datafram\" + 0.026*\"happen\" + 0.025*\"shortcut\" + 0.022*\"2005\" + 0.020*\"correctli\"\n",
            "Topic: 12 \n",
            "Words: 0.261*\"mean\" + 0.112*\"cast\" + 0.086*\"socket\" + 0.055*\"widget\" + 0.054*\"sqlalchemi\" + 0.050*\"matrix\" + 0.047*\"async\" + 0.043*\"conflict\" + 0.030*\"slower\" + 0.029*\"bound\"\n",
            "Topic: 13 \n",
            "Words: 0.220*\"event\" + 0.145*\"need\" + 0.142*\"button\" + 0.096*\"click\" + 0.077*\"better\" + 0.069*\"engin\" + 0.039*\"reflect\" + 0.037*\"game\" + 0.037*\"junit\" + 0.023*\"chain\"\n",
            "Topic: 14 \n",
            "Words: 0.410*\"css\" + 0.178*\"algorithm\" + 0.093*\"find\" + 0.056*\"accept\" + 0.054*\"advantag\" + 0.039*\"big\" + 0.024*\"power\" + 0.020*\"set\" + 0.019*\"andor\" + 0.018*\"worth\"\n",
            "Topic: 15 \n",
            "Words: 0.194*\"perform\" + 0.107*\"filter\" + 0.088*\"char\" + 0.067*\"network\" + 0.060*\"numpi\" + 0.057*\"convers\" + 0.053*\"entri\" + 0.044*\"deprec\" + 0.042*\"bodi\" + 0.039*\"emul\"\n",
            "Topic: 16 \n",
            "Words: 0.425*\"valu\" + 0.196*\"column\" + 0.135*\"attribut\" + 0.064*\"issu\" + 0.034*\"expect\" + 0.026*\"reset\" + 0.020*\"-\" + 0.016*\"distinct\" + 0.013*\"substr\" + 0.013*\"stdstring\"\n",
            "Topic: 17 \n",
            "Words: 0.208*\"date\" + 0.191*\"format\" + 0.086*\"nodej\" + 0.077*\"unabl\" + 0.064*\"appli\" + 0.057*\"certain\" + 0.048*\"root\" + 0.035*\"phone\" + 0.025*\"failur\" + 0.022*\"year\"\n",
            "Topic: 18 \n",
            "Words: 0.247*\"aspnet\" + 0.159*\"possibl\" + 0.157*\"mvc\" + 0.085*\"tool\" + 0.048*\"action\" + 0.043*\"render\" + 0.038*\"drop\" + 0.034*\"captur\" + 0.027*\"scope\" + 0.022*\"-\"\n",
            "Topic: 19 \n",
            "Words: 0.392*\"element\" + 0.231*\"connect\" + 0.075*\"avail\" + 0.039*\"facebook\" + 0.039*\"explor\" + 0.035*\"scale\" + 0.033*\"internet\" + 0.020*\"blob\" + 0.017*\"multithread\" + 0.015*\"error\"\n",
            "Topic: 20 \n",
            "Words: 0.234*\"load\" + 0.190*\"fail\" + 0.099*\"address\" + 0.051*\"definit\" + 0.050*\"error\" + 0.046*\"target\" + 0.037*\"fast\" + 0.035*\"sdk\" + 0.030*\"upgrad\" + 0.028*\"-\"\n",
            "Topic: 21 \n",
            "Words: 0.205*\"exist\" + 0.181*\"map\" + 0.168*\"develop\" + 0.102*\"compar\" + 0.071*\"pdf\" + 0.044*\"cod\" + 0.038*\"selector\" + 0.035*\"isnt\" + 0.026*\"tf\" + 0.017*\"flush\"\n",
            "Topic: 22 \n",
            "Words: 0.134*\"stop\" + 0.128*\"tab\" + 0.112*\"parent\" + 0.108*\"byte\" + 0.100*\"child\" + 0.065*\"clear\" + 0.057*\"second\" + 0.046*\"rule\" + 0.044*\"wont\" + 0.041*\"listview\"\n",
            "Topic: 23 \n",
            "Words: 0.241*\"io\" + 0.184*\"index\" + 0.077*\"complet\" + 0.072*\"keyword\" + 0.070*\"jar\" + 0.066*\"8\" + 0.041*\"11\" + 0.040*\"round\" + 0.036*\"reload\" + 0.022*\"util\"\n",
            "Topic: 24 \n",
            "Words: 0.285*\"git\" + 0.108*\"repositori\" + 0.095*\"svn\" + 0.092*\"merg\" + 0.084*\"branch\" + 0.047*\"termin\" + 0.044*\"unix\" + 0.038*\"exclud\" + 0.034*\"filenam\" + 0.031*\"spark\"\n",
            "Topic: 25 \n",
            "Words: 0.470*\"php\" + 0.147*\"null\" + 0.143*\"doesnt\" + 0.060*\"deploy\" + 0.056*\"cooki\" + 0.056*\"free\" + 0.014*\"set\" + 0.011*\"represent\" + 0.011*\"apk\" + 0.010*\"error\"\n",
            "Topic: 26 \n",
            "Words: 0.223*\"googl\" + 0.212*\"form\" + 0.161*\"local\" + 0.117*\"space\" + 0.049*\"decim\" + 0.047*\"app\" + 0.037*\"xpath\" + 0.027*\"nod\" + 0.026*\"s3\" + 0.026*\"cloud\"\n",
            "Topic: 27 \n",
            "Words: 0.197*\"tag\" + 0.093*\"catch\" + 0.090*\"password\" + 0.086*\"label\" + 0.084*\"safe\" + 0.078*\"lock\" + 0.075*\"schema\" + 0.034*\"outsid\" + 0.027*\"lead\" + 0.026*\"wordpress\"\n",
            "Topic: 28 \n",
            "Words: 0.471*\"javascript\" + 0.267*\"text\" + 0.145*\"read\" + 0.059*\"binari\" + 0.013*\"cluster\" + 0.010*\"nth\" + 0.009*\"minim\" + 0.008*\"-\" + 0.005*\"gitlab\" + 0.003*\"object\"\n",
            "Topic: 29 \n",
            "Words: 0.286*\"list\" + 0.124*\"rail\" + 0.114*\"api\" + 0.114*\"contain\" + 0.086*\"item\" + 0.069*\"configur\" + 0.046*\"emac\" + 0.040*\"edit\" + 0.023*\"true\" + 0.017*\"fals\"\n",
            "Topic: 30 \n",
            "Words: 0.267*\"script\" + 0.158*\"div\" + 0.139*\"languag\" + 0.096*\"shell\" + 0.051*\"leav\" + 0.045*\"dialog\" + 0.029*\"extra\" + 0.025*\"graphic\" + 0.024*\"listbox\" + 0.021*\"cancel\"\n",
            "Topic: 31 \n",
            "Words: 0.505*\"creat\" + 0.099*\"resourc\" + 0.071*\"powershel\" + 0.068*\"overrid\" + 0.057*\"learn\" + 0.032*\"ide\" + 0.025*\"listen\" + 0.018*\"wix\" + 0.016*\"theme\" + 0.016*\"factori\"\n",
            "Topic: 32 \n",
            "Words: 0.252*\"rubi\" + 0.134*\"xcode\" + 0.118*\"count\" + 0.090*\"datetim\" + 0.060*\"report\" + 0.057*\"constraint\" + 0.046*\"associ\" + 0.045*\"ident\" + 0.043*\"receiv\" + 0.027*\"desktop\"\n",
            "Topic: 33 \n",
            "Words: 0.224*\"implement\" + 0.168*\"size\" + 0.141*\"display\" + 0.098*\"angular\" + 0.097*\"declar\" + 0.090*\"compon\" + 0.032*\"protocol\" + 0.026*\"2\" + 0.024*\"old\" + 0.017*\"-\"\n",
            "Topic: 34 \n",
            "Words: 0.302*\"java\" + 0.193*\"object\" + 0.185*\"code\" + 0.090*\"paramet\" + 0.090*\"c_#\" + 0.075*\"new\" + 0.029*\"stream\" + 0.013*\"liter\" + 0.009*\"instanti\" + 0.006*\"error\"\n",
            "Topic: 35 \n",
            "Words: 0.187*\"color\" + 0.115*\"background\" + 0.106*\"screen\" + 0.096*\"font\" + 0.089*\"7\" + 0.074*\"chang\" + 0.049*\"origin\" + 0.045*\"special\" + 0.035*\"set\" + 0.034*\"partial\"\n",
            "Topic: 36 \n",
            "Words: 0.246*\"dictionari\" + 0.138*\"domain\" + 0.090*\"encrypt\" + 0.068*\"key\" + 0.046*\"shadow\" + 0.045*\"creation\" + 0.042*\"arrow\" + 0.042*\"jupyt\" + 0.039*\"notebook\" + 0.031*\"classpath\"\n",
            "Topic: 37 \n",
            "Words: 0.148*\"maven\" + 0.145*\"ajax\" + 0.087*\"plot\" + 0.085*\"intellij\" + 0.069*\"submit\" + 0.065*\"idea\" + 0.061*\"matplotlib\" + 0.052*\"previou\" + 0.035*\"gwt\" + 0.033*\"come\"\n",
            "Topic: 38 \n",
            "Words: 0.595*\"c++\" + 0.072*\"slow\" + 0.036*\"chart\" + 0.035*\"msbuild\" + 0.033*\"digit\" + 0.028*\"’\" + 0.027*\"3d\" + 0.024*\"system\" + 0.024*\"produc\" + 0.021*\"mix\"\n",
            "Topic: 39 \n",
            "Words: 0.159*\"django\" + 0.144*\"best\" + 0.135*\"field\" + 0.093*\"practic\" + 0.087*\"model\" + 0.078*\"option\" + 0.055*\"case\" + 0.046*\"enabl\" + 0.036*\"uniqu\" + 0.035*\"extern\"\n",
            "Topic: 40 \n",
            "Words: 0.224*\"tabl\" + 0.183*\"mysql\" + 0.087*\"input\" + 0.077*\"copi\" + 0.067*\"prevent\" + 0.063*\"specifi\" + 0.050*\"effici\" + 0.046*\"vector\" + 0.044*\"split\" + 0.043*\"length\"\n",
            "Topic: 41 \n",
            "Words: 0.431*\"string\" + 0.302*\"type\" + 0.061*\"print\" + 0.058*\"enum\" + 0.040*\"postgresql\" + 0.037*\"c_#\" + 0.030*\"constant\" + 0.022*\"transact\" + 0.006*\"stick\" + 0.004*\"error\"\n",
            "Topic: 42 \n",
            "Words: 0.142*\"miss\" + 0.132*\"aw\" + 0.103*\"handler\" + 0.069*\"bug\" + 0.053*\"consid\" + 0.051*\"term\" + 0.045*\"latest\" + 0.034*\"sublim\" + 0.034*\"panel\" + 0.033*\"alia\"\n",
            "Topic: 43 \n",
            "Words: 0.215*\"folder\" + 0.116*\"break\" + 0.103*\"integr\" + 0.074*\"highlight\" + 0.072*\"textbox\" + 0.066*\"speed\" + 0.056*\"drive\" + 0.037*\"scrollbar\" + 0.036*\"team\" + 0.030*\"echo\"\n",
            "Topic: 44 \n",
            "Words: 0.270*\"instal\" + 0.196*\"open\" + 0.154*\"sourc\" + 0.082*\"redirect\" + 0.077*\"serial\" + 0.056*\"port\" + 0.053*\"effect\" + 0.035*\"pip\" + 0.018*\"ok\" + 0.010*\"peopl\"\n",
            "Topic: 45 \n",
            "Words: 0.177*\"row\" + 0.122*\"replac\" + 0.111*\"search\" + 0.091*\"error\" + 0.087*\"exampl\" + 0.076*\"nest\" + 0.059*\"tree\" + 0.052*\"optim\" + 0.051*\"level\" + 0.042*\"intern\"\n",
            "Topic: 46 \n",
            "Words: 0.287*\"program\" + 0.102*\"ui\" + 0.086*\"caus\" + 0.083*\"stack\" + 0.075*\"usag\" + 0.042*\"launch\" + 0.039*\"particular\" + 0.036*\"cpu\" + 0.027*\"finish\" + 0.022*\"high\"\n",
            "Topic: 47 \n",
            "Words: 0.178*\"equival\" + 0.147*\"support\" + 0.127*\"hide\" + 0.099*\"--\" + 0.098*\"join\" + 0.065*\"cell\" + 0.062*\"context\" + 0.047*\"simul\" + 0.024*\"c_#\" + 0.023*\"cross\"\n",
            "Topic: 48 \n",
            "Words: 0.185*\"disabl\" + 0.115*\"simpl\" + 0.106*\"4\" + 0.077*\"correct\" + 0.063*\"releas\" + 0.062*\"recommend\" + 0.058*\"20\" + 0.051*\"gradl\" + 0.035*\"pad\" + 0.030*\"webpack\"\n",
            "Topic: 49 \n",
            "Words: 0.152*\"execut\" + 0.123*\"content\" + 0.113*\"header\" + 0.081*\"cach\" + 0.073*\"rest\" + 0.073*\"authent\" + 0.068*\"secur\" + 0.044*\"direct\" + 0.043*\"token\" + 0.037*\"inlin\"\n",
            "Topic: 50 \n",
            "Words: 0.284*\"imag\" + 0.182*\"web\" + 0.133*\"base\" + 0.124*\"browser\" + 0.073*\"chrome\" + 0.038*\"anonym\" + 0.028*\"rotat\" + 0.020*\"silverlight\" + 0.018*\"xaml\" + 0.017*\"orient\"\n",
            "Topic: 51 \n",
            "Words: 0.239*\"problem\" + 0.141*\"resiz\" + 0.131*\"mock\" + 0.106*\"setup\" + 0.089*\"distribut\" + 0.066*\"stl\" + 0.065*\"assert\" + 0.036*\"daemon\" + 0.029*\"slash\" + 0.019*\"500\"\n",
            "Topic: 52 \n",
            "Words: 0.277*\"collect\" + 0.263*\"extens\" + 0.071*\"pair\" + 0.070*\"unexpect\" + 0.046*\"bool\" + 0.044*\"unus\" + 0.044*\"png\" + 0.040*\"c_#\" + 0.024*\"portabl\" + 0.020*\"extrem\"\n",
            "Topic: 53 \n",
            "Words: 0.139*\"play\" + 0.130*\"auto\" + 0.074*\"max\" + 0.073*\"clean\" + 0.069*\"compos\" + 0.061*\"arraylist\" + 0.056*\"sound\" + 0.042*\"axi\" + 0.041*\"necessari\" + 0.036*\"min\"\n",
            "Topic: 54 \n",
            "Words: 0.603*\"android\" + 0.085*\"devic\" + 0.063*\"video\" + 0.049*\"-\" + 0.038*\"take\" + 0.032*\"want\" + 0.029*\"mail\" + 0.028*\"self\" + 0.028*\"keep\" + 0.027*\"attach\"\n",
            "Topic: 55 \n",
            "Words: 0.310*\"python\" + 0.228*\"way\" + 0.101*\"html\" + 0.088*\"page\" + 0.070*\"best\" + 0.056*\"modul\" + 0.056*\"name\" + 0.024*\"standard\" + 0.020*\"extract\" + 0.012*\"timestamp\"\n",
            "Topic: 56 \n",
            "Words: 0.144*\"x\" + 0.124*\"mac\" + 0.123*\"os\" + 0.104*\"random\" + 0.078*\"trigger\" + 0.059*\"look\" + 0.053*\"f\" + 0.045*\"#\" + 0.033*\"opencv\" + 0.032*\"raw\"\n",
            "Topic: 57 \n",
            "Words: 0.140*\"pattern\" + 0.091*\"invalid\" + 0.083*\"equal\" + 0.074*\"keyboard\" + 0.073*\"switch\" + 0.072*\"haskel\" + 0.068*\"faster\" + 0.058*\"firefox\" + 0.048*\"border\" + 0.044*\"append\"\n",
            "Topic: 58 \n",
            "Words: 0.311*\"add\" + 0.176*\"custom\" + 0.103*\"loop\" + 0.091*\"iter\" + 0.066*\"condit\" + 0.054*\"structur\" + 0.027*\"vba\" + 0.019*\"transform\" + 0.018*\"compat\" + 0.017*\"-\"\n",
            "Topic: 59 \n",
            "Words: 0.128*\"manag\" + 0.115*\"regex\" + 0.097*\"task\" + 0.088*\"environ\" + 0.081*\"namespac\" + 0.075*\"apach\" + 0.070*\"solut\" + 0.059*\"graph\" + 0.044*\"azur\" + 0.034*\"occur\"\n",
            "Topic: 60 \n",
            "Words: 0.204*\"like\" + 0.166*\"send\" + 0.092*\"duplic\" + 0.075*\"tell\" + 0.074*\"mongodb\" + 0.064*\"center\" + 0.044*\"histori\" + 0.042*\"final\" + 0.040*\"diff\" + 0.022*\"uiwebview\"\n",
            "Topic: 61 \n",
            "Words: 0.388*\"class\" + 0.154*\"librari\" + 0.105*\"static\" + 0.086*\"depend\" + 0.056*\"react\" + 0.050*\"share\" + 0.039*\"nativ\" + 0.035*\"inject\" + 0.024*\"c_#\" + 0.015*\"helper\"\n",
            "Topic: 62 \n",
            "Words: 0.313*\"charact\" + 0.160*\"automat\" + 0.081*\"combin\" + 0.076*\"ip\" + 0.066*\"unicod\" + 0.056*\"microsoft\" + 0.052*\"utf-8\" + 0.033*\"tensorflow\" + 0.030*\"onclick\" + 0.020*\"polici\"\n",
            "Topic: 63 \n",
            "Words: 0.298*\"refer\" + 0.176*\"result\" + 0.137*\"commit\" + 0.062*\"selenium\" + 0.049*\"comma\" + 0.044*\"present\" + 0.035*\"twice\" + 0.026*\"osx\" + 0.021*\"-\" + 0.019*\"webdriv\"\n",
            "Topic: 64 \n",
            "Words: 0.483*\"use\" + 0.098*\"get\" + 0.083*\"valid\" + 0.077*\"current\" + 0.046*\"activ\" + 0.035*\"doubl\" + 0.031*\"float\" + 0.030*\"hibern\" + 0.028*\"global\" + 0.026*\"emb\"\n",
            "Topic: 65 \n",
            "Words: 0.201*\"studio\" + 0.176*\"visual\" + 0.157*\"remov\" + 0.084*\"start\" + 0.062*\"document\" + 0.056*\"requir\" + 0.046*\"excel\" + 0.044*\"modifi\" + 0.038*\"throw\" + 0.029*\"tri\"\n",
            "Topic: 66 \n",
            "Words: 0.249*\"work\" + 0.221*\"gener\" + 0.102*\"oper\" + 0.074*\"insert\" + 0.071*\"initi\" + 0.059*\"vim\" + 0.047*\"mode\" + 0.036*\"long\" + 0.024*\"batch\" + 0.021*\"dont\"\n",
            "Topic: 67 \n",
            "Words: 0.272*\"variabl\" + 0.144*\"write\" + 0.130*\"framework\" + 0.120*\"good\" + 0.081*\"entiti\" + 0.078*\"style\" + 0.076*\"instanc\" + 0.039*\"bad\" + 0.021*\"architectur\" + 0.019*\"set\"\n",
            "Topic: 68 \n",
            "Words: 0.275*\"view\" + 0.181*\"json\" + 0.092*\"upload\" + 0.069*\"layout\" + 0.065*\"right\" + 0.056*\"focu\" + 0.055*\"editor\" + 0.034*\"debugg\" + 0.026*\"uiview\" + 0.020*\"composit\"\n",
            "Topic: 69 \n",
            "Words: 0.141*\"swift\" + 0.132*\"warn\" + 0.129*\"#\" + 0.122*\"inherit\" + 0.107*\"objective-c\" + 0.062*\"abstract\" + 0.060*\"crash\" + 0.059*\"proxi\" + 0.039*\"closur\" + 0.026*\"c++11\"\n",
            "Topic: 70 \n",
            "Words: 0.410*\"window\" + 0.285*\"run\" + 0.175*\"wpf\" + 0.046*\"rang\" + 0.022*\"track\" + 0.012*\"35\" + 0.010*\"-\" + 0.009*\"ef\" + 0.008*\"explan\" + 0.007*\"ci\"\n",
            "Topic: 71 \n",
            "Words: 0.325*\"convert\" + 0.320*\"return\" + 0.087*\"session\" + 0.051*\"dll\" + 0.039*\"cursor\" + 0.025*\"actual\" + 0.024*\"drag\" + 0.023*\"directli\" + 0.022*\"textarea\" + 0.020*\"dump\"\n",
            "Topic: 72 \n",
            "Words: 0.214*\"thread\" + 0.157*\"3\" + 0.104*\"separ\" + 0.065*\"zero\" + 0.040*\"alloc\" + 0.039*\"jdbc\" + 0.038*\"interpret\" + 0.038*\"newlin\" + 0.032*\"coordin\" + 0.032*\"pixel\"\n",
            "Topic: 73 \n",
            "Words: 0.251*\"properti\" + 0.228*\"user\" + 0.135*\"bind\" + 0.076*\"locat\" + 0.046*\"object\" + 0.044*\"struct\" + 0.033*\"-\" + 0.021*\"b\" + 0.018*\"c_#\" + 0.018*\"typeerror\"\n",
            "Topic: 74 \n",
            "Words: 0.288*\"singl\" + 0.186*\"save\" + 0.099*\"extend\" + 0.081*\"buffer\" + 0.067*\"transpar\" + 0.055*\"press\" + 0.035*\"stdout\" + 0.029*\"individu\" + 0.027*\"sit\" + 0.025*\"expos\"\n",
            "Topic: 75 \n",
            "Words: 0.283*\"method\" + 0.183*\"line\" + 0.151*\"command\" + 0.085*\"argument\" + 0.083*\"dynam\" + 0.056*\"constructor\" + 0.055*\"client\" + 0.024*\"main\" + 0.021*\"pass\" + 0.014*\"normal\"\n",
            "Topic: 76 \n",
            "Words: 0.279*\"directori\" + 0.140*\"give\" + 0.137*\"group\" + 0.077*\"symbol\" + 0.074*\"websit\" + 0.071*\"virtual\" + 0.070*\"undefin\" + 0.027*\"plain\" + 0.024*\"error\" + 0.017*\"activ\"\n",
            "Topic: 77 \n",
            "Words: 0.216*\"match\" + 0.096*\"node\" + 0.089*\"profil\" + 0.074*\"push\" + 0.072*\"identifi\" + 0.060*\"notif\" + 0.058*\"n\" + 0.044*\"autom\" + 0.038*\"bundl\" + 0.034*\"truncat\"\n",
            "Topic: 78 \n",
            "Words: 0.181*\"control\" + 0.178*\"time\" + 0.108*\"memori\" + 0.083*\"determin\" + 0.073*\"set\" + 0.061*\"integ\" + 0.049*\"show\" + 0.046*\"laravel\" + 0.038*\"delphi\" + 0.035*\"common\"\n",
            "Topic: 79 \n",
            "Words: 0.353*\"server\" + 0.348*\"sql\" + 0.130*\"compil\" + 0.036*\"gcc\" + 0.035*\"wrong\" + 0.019*\"ms\" + 0.018*\"disk\" + 0.011*\"angular2\" + 0.009*\"xsd\" + 0.007*\"criteria\"\n",
            "Topic: 80 \n",
            "Words: 0.219*\"key\" + 0.169*\"updat\" + 0.146*\"insid\" + 0.074*\"width\" + 0.071*\"oracl\" + 0.070*\"docker\" + 0.048*\"icon\" + 0.036*\"foreign\" + 0.034*\"regist\" + 0.033*\"primari\"\n",
            "Topic: 81 \n",
            "Words: 0.164*\"pars\" + 0.147*\"int\" + 0.143*\"perl\" + 0.113*\"record\" + 0.090*\"lambda\" + 0.053*\"concaten\" + 0.049*\"synchron\" + 0.045*\"deleg\" + 0.041*\"rspec\" + 0.041*\"express\"\n",
            "Topic: 82 \n",
            "Words: 0.344*\"check\" + 0.152*\"programmat\" + 0.112*\"design\" + 0.066*\"angularj\" + 0.047*\"refresh\" + 0.038*\"bite\" + 0.033*\"cc++\" + 0.029*\"set\" + 0.027*\"letter\" + 0.025*\"elasticsearch\"\n",
            "Topic: 83 \n",
            "Words: 0.168*\"id\" + 0.133*\"assembl\" + 0.124*\"altern\" + 0.066*\"site\" + 0.062*\"properli\" + 0.059*\"versu\" + 0.053*\"quot\" + 0.052*\"mobil\" + 0.050*\"rel\" + 0.041*\"inner\"\n",
            "Topic: 84 \n",
            "Words: 0.161*\"interfac\" + 0.158*\"import\" + 0.070*\"resolv\" + 0.063*\"certif\" + 0.052*\"ssl\" + 0.043*\"sequenc\" + 0.040*\"npm\" + 0.036*\"pool\" + 0.034*\"section\" + 0.033*\"error\"\n",
            "Topic: 85 \n",
            "Words: 0.209*\"app\" + 0.152*\"default\" + 0.126*\"iphon\" + 0.118*\"express\" + 0.059*\"regular\" + 0.059*\"word\" + 0.056*\"limit\" + 0.032*\"gui\" + 0.030*\"winform\" + 0.026*\"dom\"\n",
            "Topic: 86 \n",
            "Words: 0.291*\"jqueri\" + 0.242*\"chang\" + 0.073*\"sort\" + 0.057*\"scroll\" + 0.047*\"bar\" + 0.040*\"bootstrap\" + 0.033*\"place\" + 0.026*\"revers\" + 0.026*\"ifram\" + 0.024*\"prefer\"\n",
            "Topic: 87 \n",
            "Words: 0.367*\"data\" + 0.073*\"core\" + 0.052*\"provid\" + 0.047*\"featur\" + 0.046*\"typescript\" + 0.045*\"annot\" + 0.044*\"migrat\" + 0.041*\"maximum\" + 0.040*\"flutter\" + 0.037*\"relat\"\n",
            "Topic: 88 \n",
            "Words: 0.400*\"what\" + 0.082*\"titl\" + 0.079*\"box\" + 0.056*\"macro\" + 0.056*\"increas\" + 0.055*\"choos\" + 0.051*\"way\" + 0.037*\"interact\" + 0.032*\"combobox\" + 0.029*\"c_#\"\n",
            "Topic: 89 \n",
            "Words: 0.311*\"vs\" + 0.107*\"except\" + 0.106*\"request\" + 0.097*\"http\" + 0.076*\"+\" + 0.059*\"post\" + 0.052*\"point\" + 0.028*\"-\" + 0.027*\"html5\" + 0.021*\"real\"\n",
            "Topic: 90 \n",
            "Words: 0.184*\"member\" + 0.130*\"privat\" + 0.121*\"0\" + 0.121*\"recurs\" + 0.088*\"const\" + 0.061*\"manual\" + 0.057*\"2010\" + 0.031*\"signal\" + 0.028*\"edittext\" + 0.027*\"popup\"\n",
            "Topic: 91 \n",
            "Words: 0.738*\"file\" + 0.086*\"delet\" + 0.025*\"statu\" + 0.024*\"csv\" + 0.019*\"overload\" + 0.018*\"ubuntu\" + 0.012*\"dot\" + 0.011*\"javafx\" + 0.010*\"atom\" + 0.010*\"master\"\n",
            "Topic: 92 \n",
            "Words: 0.354*\"databas\" + 0.190*\"templat\" + 0.090*\"forc\" + 0.084*\"download\" + 0.042*\"frame\" + 0.034*\"increment\" + 0.025*\"flag\" + 0.025*\"decod\" + 0.020*\"success\" + 0.019*\"occurr\"\n",
            "Topic: 93 \n",
            "Words: 0.133*\"1\" + 0.123*\"fix\" + 0.096*\"sign\" + 0.085*\"escap\" + 0.062*\"tomcat\" + 0.047*\"similar\" + 0.044*\"jenkin\" + 0.039*\"unsign\" + 0.037*\"pipelin\" + 0.035*\"vuej\"\n",
            "Topic: 94 \n",
            "Words: 0.158*\"scala\" + 0.086*\"timeout\" + 0.083*\"claus\" + 0.079*\"nhibern\" + 0.067*\"exit\" + 0.064*\"vertic\" + 0.062*\"appear\" + 0.058*\"fragment\" + 0.046*\"horizont\" + 0.045*\"kill\"\n",
            "Topic: 95 \n",
            "Words: 0.272*\"linux\" + 0.158*\"bash\" + 0.131*\"hash\" + 0.082*\"draw\" + 0.071*\"wrap\" + 0.053*\"cocoa\" + 0.040*\"numer\" + 0.039*\"cmake\" + 0.036*\"cli\" + 0.029*\"base64\"\n",
            "Topic: 96 \n",
            "Words: 0.158*\"wcf\" + 0.134*\"anim\" + 0.098*\"permiss\" + 0.094*\"question\" + 0.070*\"public\" + 0.067*\"enter\" + 0.061*\"proper\" + 0.059*\"basic\" + 0.048*\"ant\" + 0.046*\"deriv\"\n",
            "Topic: 97 \n",
            "Words: 0.253*\"applic\" + 0.210*\"net\" + 0.175*\"project\" + 0.103*\"eclips\" + 0.098*\"handl\" + 0.025*\"jpa\" + 0.021*\"turn\" + 0.020*\"error\" + 0.017*\"heap\" + 0.015*\"indic\"\n",
            "Topic: 98 \n",
            "Words: 0.262*\"queri\" + 0.162*\"linq\" + 0.159*\"specif\" + 0.083*\"sql\" + 0.069*\"assign\" + 0.034*\"sum\" + 0.032*\"vbnet\" + 0.027*\"unknown\" + 0.025*\"help\" + 0.022*\"-\"\n",
            "Topic: 99 \n",
            "Words: 0.356*\"access\" + 0.109*\"larg\" + 0.079*\"retriev\" + 0.063*\"make\" + 0.048*\"fastest\" + 0.047*\"guid\" + 0.044*\"renam\" + 0.038*\"fit\" + 0.032*\"deni\" + 0.024*\"small\"\n"
          ]
        }
      ],
      "source": [
        "# Print all topics and their token composants\n",
        "for idx, topic in title_lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6ps2hL-EPMM"
      },
      "source": [
        "## 3.3 Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boPraLo-EK0-"
      },
      "source": [
        "Now we test the hypothesis of tags appearing in the themes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Q1kELgOulb"
      },
      "outputs": [],
      "source": [
        "# Given the index of the question print the pre processing pipeline and the score\n",
        "def infer_topic_score(sample_idx, bow_corpus):\n",
        "  for index, score in sorted(title_lda_model[bow_corpus[sample_idx]], key=lambda tup: -1*tup[1]):\n",
        "      print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, title_lda_model.print_topic(index, 10)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bFrqzJEVsc"
      },
      "source": [
        "Indeed we observe that the tags are present in at least some of the topics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOlZ_UQ_PA5j",
        "outputId": "3a7c3535-27f9-4b58-bca5-0b0883ae8162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################Processing#####################\n",
            "sample idx: 1\n",
            "sample tags: ['ios', 'iphone', 'xcode', 'ios7', 'xcode5']\n",
            "\n",
            "processing pipeline: \n",
            "\n",
            "sample title: Xcode error : Distill failed for unknown reasons\n",
            "preprocessed title: ['microsoft', 'offic', '2007', 'file', 'type', 'mime', 'type', 'identifi', 'charact']\n",
            "bow_corpus of title: [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]\n",
            "\n",
            "bag of words equivalence: \n",
            "Word 5 (\"error\") appears 1 time.\n",
            "Word 6 (\"fail\") appears 1 time.\n",
            "Word 7 (\"reason\") appears 1 time.\n",
            "Word 8 (\"unknown\") appears 1 time.\n",
            "Word 9 (\"xcode\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "idx = 1\n",
        "print(\"###################Processing#####################\")\n",
        "sample_nlp_pipeline(idx, df, title_bow_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctlXPa3D6T4C",
        "outputId": "02363d04-f3f1-4f4d-9276-ed2aadcecf96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################Inference######################\n",
            "\n",
            "Score: 0.3033624589443207\t \n",
            "Topic: 0.234*\"load\" + 0.190*\"fail\" + 0.099*\"address\" + 0.051*\"definit\" + 0.050*\"error\" + 0.046*\"target\" + 0.037*\"fast\" + 0.035*\"sdk\" + 0.030*\"upgrad\" + 0.028*\"-\"\n",
            "\n",
            "Score: 0.18693606555461884\t \n",
            "Topic: 0.262*\"queri\" + 0.162*\"linq\" + 0.159*\"specif\" + 0.083*\"sql\" + 0.069*\"assign\" + 0.034*\"sum\" + 0.032*\"vbnet\" + 0.027*\"unknown\" + 0.025*\"help\" + 0.022*\"-\"\n",
            "\n",
            "Score: 0.18136711418628693\t \n",
            "Topic: 0.252*\"rubi\" + 0.134*\"xcode\" + 0.118*\"count\" + 0.090*\"datetim\" + 0.060*\"report\" + 0.057*\"constraint\" + 0.046*\"associ\" + 0.045*\"ident\" + 0.043*\"receiv\" + 0.027*\"desktop\"\n",
            "\n",
            "Score: 0.16833244264125824\t \n",
            "Topic: 0.240*\"spring\" + 0.232*\"debug\" + 0.085*\"sqlite\" + 0.079*\"machin\" + 0.067*\"reason\" + 0.047*\"boot\" + 0.039*\"bean\" + 0.032*\"driver\" + 0.032*\"transit\" + 0.029*\"busi\"\n"
          ]
        }
      ],
      "source": [
        "print(\"###################Inference######################\")\n",
        "infer_topic_score(idx, title_bow_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTMWJY7NQqlv",
        "outputId": "b24e208f-c130-4284-d299-761344d536b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################Processing#####################\n",
            "sample idx: 11010\n",
            "sample tags: ['html', 'css', 'forms']\n",
            "\n",
            "processing pipeline: \n",
            "\n",
            "sample title: Why use definition lists (DL,DD,DT) tags for HTML forms instead of tables?\n",
            "preprocessed title: ['aspnet', 'mvc', '-', 'view', 'master', 'page', 'set', 'titl']\n",
            "bow_corpus of title: [(20, 1), (38, 1), (108, 1), (161, 1), (163, 1), (284, 1), (293, 1), (790, 1)]\n",
            "\n",
            "bag of words equivalence: \n",
            "Word 20 (\"use\") appears 1 time.\n",
            "Word 38 (\"list\") appears 1 time.\n",
            "Word 108 (\"instead\") appears 1 time.\n",
            "Word 161 (\"html\") appears 1 time.\n",
            "Word 163 (\"tag\") appears 1 time.\n",
            "Word 284 (\"tabl\") appears 1 time.\n",
            "Word 293 (\"form\") appears 1 time.\n",
            "Word 790 (\"definit\") appears 1 time.\n",
            "\n",
            "###################Inference######################\n",
            "\n",
            "Score: 0.11222319304943085\t \n",
            "Topic: 0.483*\"use\" + 0.098*\"get\" + 0.083*\"valid\" + 0.077*\"current\" + 0.046*\"activ\" + 0.035*\"doubl\" + 0.031*\"float\" + 0.030*\"hibern\" + 0.028*\"global\" + 0.026*\"emb\"\n",
            "\n",
            "Score: 0.11222290247678757\t \n",
            "Topic: 0.286*\"list\" + 0.124*\"rail\" + 0.114*\"api\" + 0.114*\"contain\" + 0.086*\"item\" + 0.069*\"configur\" + 0.046*\"emac\" + 0.040*\"edit\" + 0.023*\"true\" + 0.017*\"fals\"\n",
            "\n",
            "Score: 0.11222271621227264\t \n",
            "Topic: 0.224*\"tabl\" + 0.183*\"mysql\" + 0.087*\"input\" + 0.077*\"copi\" + 0.067*\"prevent\" + 0.063*\"specifi\" + 0.050*\"effici\" + 0.046*\"vector\" + 0.044*\"split\" + 0.043*\"length\"\n",
            "\n",
            "Score: 0.11222266405820847\t \n",
            "Topic: 0.223*\"googl\" + 0.212*\"form\" + 0.161*\"local\" + 0.117*\"space\" + 0.049*\"decim\" + 0.047*\"app\" + 0.037*\"xpath\" + 0.027*\"nod\" + 0.026*\"s3\" + 0.026*\"cloud\"\n",
            "\n",
            "Score: 0.1122225970029831\t \n",
            "Topic: 0.197*\"tag\" + 0.093*\"catch\" + 0.090*\"password\" + 0.086*\"label\" + 0.084*\"safe\" + 0.078*\"lock\" + 0.075*\"schema\" + 0.034*\"outsid\" + 0.027*\"lead\" + 0.026*\"wordpress\"\n",
            "\n",
            "Score: 0.1122216284275055\t \n",
            "Topic: 0.310*\"python\" + 0.228*\"way\" + 0.101*\"html\" + 0.088*\"page\" + 0.070*\"best\" + 0.056*\"modul\" + 0.056*\"name\" + 0.024*\"standard\" + 0.020*\"extract\" + 0.012*\"timestamp\"\n",
            "\n",
            "Score: 0.1122211217880249\t \n",
            "Topic: 0.245*\"test\" + 0.115*\"url\" + 0.113*\"xml\" + 0.080*\"instead\" + 0.079*\"unit\" + 0.079*\"r\" + 0.079*\"packag\" + 0.077*\"link\" + 0.074*\"includ\" + 0.012*\"head\"\n",
            "\n",
            "Score: 0.11221973598003387\t \n",
            "Topic: 0.234*\"load\" + 0.190*\"fail\" + 0.099*\"address\" + 0.051*\"definit\" + 0.050*\"error\" + 0.046*\"target\" + 0.037*\"fast\" + 0.035*\"sdk\" + 0.030*\"upgrad\" + 0.028*\"-\"\n"
          ]
        }
      ],
      "source": [
        "idx = 11010\n",
        "print(\"###################Processing#####################\")\n",
        "sample_nlp_pipeline(idx, df, title_bow_corpus)\n",
        "print(\"\\n###################Inference######################\")\n",
        "infer_topic_score(idx, title_bow_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvC63jhYEelU"
      },
      "source": [
        "We can also test on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PtUOkdcQvR-",
        "outputId": "1e86485b-96cd-4032-8a7a-979f7f1e68da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n",
            "Score: 0.25250110030174255\t Topic: 0.302*\"java\" + 0.193*\"object\" + 0.185*\"code\" + 0.090*\"paramet\" + 0.090*\"c_#\"\n",
            "33\n",
            "Score: 0.2524997889995575\t Topic: 0.224*\"implement\" + 0.168*\"size\" + 0.141*\"display\" + 0.098*\"angular\" + 0.097*\"declar\"\n",
            "73\n",
            "Score: 0.25249752402305603\t Topic: 0.251*\"properti\" + 0.228*\"user\" + 0.135*\"bind\" + 0.076*\"locat\" + 0.046*\"object\"\n"
          ]
        }
      ],
      "source": [
        "# test on unseen data\n",
        "unseen_title = 'How can I declare a struct in java'\n",
        "bow_vector = title_dictionary.doc2bow(preprocess(unseen_title))\n",
        "for index, score in sorted(title_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(index)\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, title_lda_model.print_topic(index, 5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAqzlqP9lTGz"
      },
      "source": [
        "And finally, on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaSQq9MmlX2n",
        "outputId": "20725758-0021-4a13-d14f-36834f2b3f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###################Processing#####################\n",
            "sample idx: 10\n",
            "sample tags: ['git', 'bitbucket', 'git-branch']\n",
            "\n",
            "processing pipeline: \n",
            "\n",
            "sample title: Delete branches in Bitbucket\n",
            "preprocessed title: ['aspnet', 'site', 'map']\n",
            "bow_corpus of title: [(136, 1), (679, 1), (1979, 1)]\n",
            "\n",
            "bag of words equivalence: \n",
            "Word 136 (\"delet\") appears 1 time.\n",
            "Word 679 (\"branch\") appears 1 time.\n",
            "Word 1979 (\"bitbucket\") appears 1 time.\n",
            "###################Inference######################\n",
            "\n",
            "Score: 0.25250568985939026\t \n",
            "Topic: 0.738*\"file\" + 0.086*\"delet\" + 0.025*\"statu\" + 0.024*\"csv\" + 0.019*\"overload\" + 0.018*\"ubuntu\" + 0.012*\"dot\" + 0.011*\"javafx\" + 0.010*\"atom\" + 0.010*\"master\"\n",
            "\n",
            "Score: 0.2525056302547455\t \n",
            "Topic: 0.285*\"git\" + 0.108*\"repositori\" + 0.095*\"svn\" + 0.092*\"merg\" + 0.084*\"branch\" + 0.047*\"termin\" + 0.044*\"unix\" + 0.038*\"exclud\" + 0.034*\"filenam\" + 0.031*\"spark\"\n",
            "\n",
            "Score: 0.25248122215270996\t \n",
            "Topic: 0.147*\"posit\" + 0.115*\"end\" + 0.102*\"height\" + 0.068*\"t-sql\" + 0.065*\"ssh\" + 0.053*\"absolut\" + 0.049*\"100\" + 0.040*\"reduc\" + 0.039*\"exe\" + 0.034*\"fatal\"\n"
          ]
        }
      ],
      "source": [
        "idx = 10\n",
        "print(\"###################Processing#####################\")\n",
        "sample_nlp_pipeline(idx, test, test_title_bow_corpus)\n",
        "print(\"###################Inference######################\")\n",
        "infer_topic_score(idx, test_title_bow_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlI6lnOREyGD"
      },
      "source": [
        "### Initial conclusion of LDA results:\n",
        "We can observe that our hypothesis that the resulting LDA model would encode the questions that are represented by tags into different topics seems to hold. Furthermore it seems to work on the test set as we observe ground truth tags in the topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InuxPALhxtzo"
      },
      "source": [
        "## 3.4 Tags proposals from title topics\n",
        "\n",
        "Now that we have a model capable of defining topics from titles, we can use the result of the inference to generate Tag predictions. Here we will use the topic confidence and each composant of the tokens of each topic. Since we are using an unsupervised approach we will extract tags using simply the confidence terms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYhs2dn6FlhS"
      },
      "source": [
        "#### Proposed approach:\n",
        "We will extract topic tags from a string of text and compare it with a set of available tokenized tags. If there is a match and it passes a confidence check, it is a tag suggestion and we obtain it using the tag2dict mapping. This allows us to not miss on predictions because the token is different than the tag."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6FDhMDAGF7M"
      },
      "source": [
        "First we need to preprcess the new sentence. Then, it is converted to the BOW representation used to train the LDA model. Inference is performed on this BOW set. We verfy that that using token2tag increases the probability of matches between suggestions and existing tags!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy6s_bPjzxXh"
      },
      "outputs": [],
      "source": [
        "# extract tag proposals from topics\n",
        "unseen_title = 'How can I declare a variable in python'\n",
        "bow_vector = title_dictionary.doc2bow(preprocess(unseen_title))\n",
        "\n",
        "scores = []\n",
        "words = []\n",
        "for index, score in sorted(title_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "\n",
        "    scores.append(score)\n",
        "    words.append(title_lda_model.get_topic_terms(index, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNrMbqBF5-bx",
        "outputId": "d2aefcf7-6a52-49de-9e5b-b8c4f4866eb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(33, 0.2524989), (55, 0.2525002), (67, 0.25250015)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "title_lda_model[bow_vector]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F573r7itGbt6"
      },
      "source": [
        "Check if there are matches with existing tags matches before applying token2tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L63OV02_2W7s",
        "outputId": "75f48bb9-d06b-466b-dd21-08f4b976ffbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common tags: ['python', 'html']\n"
          ]
        }
      ],
      "source": [
        "common_tags = []\n",
        "# compare with dict of tags\n",
        "for bow_id, score in words[0]:\n",
        "  if title_dictionary[bow_id] in tags_array:\n",
        "    common_tags.append(title_dictionary[bow_id])\n",
        "\n",
        "print('common tags: {}'.format(common_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP2xc2VDnUgh"
      },
      "source": [
        "Check if there are matches with existing tags after applying token2tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh5flJqwm-6x",
        "outputId": "ee21c8f6-1fa9-4d53-b2d4-94d953a9f658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "common tags: ['python', 'html', 'page']\n"
          ]
        }
      ],
      "source": [
        "common_tags = []\n",
        "# compare with dict of tags\n",
        "for bow_id, score in words[0]:\n",
        "  token = title_dictionary[bow_id]\n",
        "  # try to convert token2tag, else leave tag as is\n",
        "  tag = ''\n",
        "  if token in token2tag_dict.keys():\n",
        "    tag = token2tag_dict[token]\n",
        "  else:\n",
        "    tag = token\n",
        "  if tag in tags_array:\n",
        "    common_tags.append(title_dictionary[bow_id])\n",
        "\n",
        "print('common tags: {}'.format(common_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xdHlkseHD4k"
      },
      "source": [
        "Simply comparing for common tokens between the title and the set of tags would possibly work. However the LDA model approach allows for less computations and also provides a score that we can use to refine the prediction.\n",
        "\n",
        "We have two scores per proposal. The overall confidence on the topic and then, for each topic, a score that represents token contribution to the topic.\n",
        "\n",
        "Here we extract both scores of the topics and individual tokens to refine the tag proposal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDxVZGD75XKy"
      },
      "outputs": [],
      "source": [
        "# Extract topic score and individual token scores\n",
        "title_token_score = []\n",
        "title_topic_proposal = []\n",
        "for index, topic_score in sorted(title_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    words = title_lda_model.get_topic_terms(index, 5)\n",
        "    # compare with dict of tags\n",
        "    for bow_id, score in words:\n",
        "      if title_dictionary[bow_id] in tags_array:\n",
        "        title_topic_proposal.append(title_dictionary[bow_id])\n",
        "        title_token_score.append((topic_score, score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xscsdgcIHhe3"
      },
      "source": [
        "Print the scores for each token of the title. We observe that in this case the individual token score is high, but the topic score is approximately the same for all found topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgjY08IL6mku",
        "outputId": "e8adec7b-6210-4f27-a39e-97b2e2bee10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag : python, topic score : 0.2525002360343933, individual token score : 0.3098738193511963\n",
            "tag : html, topic score : 0.2525002360343933, individual token score : 0.10073015838861465\n",
            "tag : size, topic score : 0.25249892473220825, individual token score : 0.16774149239063263\n",
            "tag : display, topic score : 0.25249892473220825, individual token score : 0.1414836049079895\n",
            "tag : angular, topic score : 0.25249892473220825, individual token score : 0.09769216179847717\n"
          ]
        }
      ],
      "source": [
        "for tag, score in zip(title_topic_proposal, title_token_score):\n",
        "  print('tag : {}, topic score : {}, individual token score : {}'.format(tag, score[0], score[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGaqpcX1Ip_6"
      },
      "source": [
        "With the scores we now can threshold the result and obtain a refined tag suggestion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyB0hcCE7bB3",
        "outputId": "9f74b1e0-6c7d-4f10-b705-0a981a190f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag : python ##### topic score : 0.2525002360343933 ##### individual score : 0.3098738193511963\n",
            "tag : html ##### topic score : 0.2525002360343933 ##### individual score : 0.10073015838861465\n",
            "tag : size ##### topic score : 0.25249892473220825 ##### individual score : 0.16774149239063263\n",
            "tag : display ##### topic score : 0.25249892473220825 ##### individual score : 0.1414836049079895\n"
          ]
        }
      ],
      "source": [
        "# catch a tag given a threshold\n",
        "title_tag_thresh = 0.1\n",
        "for tag, score in zip(title_topic_proposal, title_token_score):\n",
        "  if score[1] > title_tag_thresh:\n",
        "    print('tag : {} ##### topic score : {} ##### individual score : {}'.format(tag, score[0], score[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOYlyXkRI0MZ"
      },
      "source": [
        "Since this is a suggestion system, we want to have high recall since giving a tag is better than no tag at all.\n",
        "\n",
        "The final prediction list is the union between the confidence analysis and the tags present in the text.  If we use the intersection we will restrict the tags to the already existent tags. On the other hand using the individual token scores allows for the inclusion of new tags if they were already present before training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70luDu4KJitn"
      },
      "outputs": [],
      "source": [
        "# Tag suggestion:\n",
        "def lda_tag_suggestion(input_string, lda_model, corpus_dictionary,\n",
        "                       token2tag_dict, n_proposals = 5, topic_thresh = 0.0,\n",
        "                       token_thresh = 0.1, n_tags = 1000, new_tags = False, token2tag = True, verbose = True):\n",
        "  \"\"\"\n",
        "  :input_string: string of text representing the title\n",
        "  :lda_model: LDA model trained on corpus_dictionary\n",
        "  :corpus_dictionary: Token dictionary\n",
        "  :token2tag_dict: Token to tag encoding dictionary\n",
        "  :n_proposals: maximum number of proposals\n",
        "  :token2tag: set to False to disable token2tag\n",
        "  :token2tag: set to True to accept new tags\n",
        "  :title_topic_thresh: trim proposals based on topic score (default = 0)\n",
        "  :title_token_thresh: trim proposals based on individual token score (default = 0.1)\n",
        "  :verbose: silences function (default = False)\n",
        "\n",
        "  :return: List of tag suggestions\n",
        "  \"\"\"\n",
        "  # extract tag proposals from topics\n",
        "  bow_vector = corpus_dictionary.doc2bow(preprocess(input_string))\n",
        "\n",
        "  # Extract topic score and individual token scores\n",
        "  token_scores = []\n",
        "  proposals = []\n",
        "  for index, topic_score in sorted(title_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    topic_composants = title_lda_model.get_topic_terms(index, 5)\n",
        "    # check topic score\n",
        "    if topic_score > topic_thresh:\n",
        "      # enter topic composition\n",
        "      for bow_id, token_score in topic_composants:\n",
        "        # check token score\n",
        "        if token_score > token_thresh:\n",
        "          # compare with dict of tags\n",
        "          token = corpus_dictionary[bow_id]\n",
        "          tag = ''\n",
        "          if token2tag:\n",
        "            tag = token2tag_dict.get(token)\n",
        "\n",
        "            if (tag == '' or tag == None) and new_tags:\n",
        "              tag = token\n",
        "          else:\n",
        "            tag = token\n",
        "          if tag != '' and tag != None:\n",
        "            proposals.append(tag)\n",
        "            token_scores.append(token_score)\n",
        "            if verbose:\n",
        "              print('tag : {} ##### topic score : {} ##### individual score : {}'.format(tag, topic_score, token_score))\n",
        "\n",
        "\n",
        "  ordering = np.arange(len(proposals))\n",
        "  proposals = np.array(proposals)\n",
        "  token_scores = np.array(token_scores)\n",
        "  # select top n_proposals by score:\n",
        "  if len(proposals) > n_proposals:\n",
        "    ordering = np.argsort(token_scores)\n",
        "    proposals = proposals[ordering]\n",
        "    token_scores = token_scores[ordering]\n",
        "    return proposals[:n_proposals],token_scores[:n_proposals]\n",
        "  else:\n",
        "    return proposals, token_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8KhwviaNXzr"
      },
      "source": [
        "Now we test the suggestion pipeline:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-JdiRdzPy2F"
      },
      "source": [
        "For sanity check we bserve that a string that is not working (possibly because tokenization did not work outputs no tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UFbFmZ8NWsw",
        "outputId": "c07a8246-2be4-447c-c158-ce85db6cc476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag proposals = (array([], dtype=float64), array([], dtype=float64))\n"
          ]
        }
      ],
      "source": [
        "test_str = ''\n",
        "proposed_tags = lda_tag_suggestion(input_string = test_str, lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = True)\n",
        "print('tag proposals = {}'.format(proposed_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dupgw8NLQG3u"
      },
      "source": [
        "Now we chec the result with a small string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwzkPw9BPqyg",
        "outputId": "06903fa6-afe3-4306-c7f3-d14ff8948ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag : uses ##### topic score : 0.5049919486045837 ##### individual score : 0.48298272490501404\n",
            "tag proposals = ['uses']\n"
          ]
        }
      ],
      "source": [
        "test_str = 'Hello world'\n",
        "proposed_tags,ps = lda_tag_suggestion(input_string = test_str, lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = True)\n",
        "print('tag proposals = {}'.format(proposed_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcGcZOKQQKdJ"
      },
      "source": [
        "Now with a possible title:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VLB1bnSQjkJ",
        "outputId": "42bb7954-a748-4eb9-aae8-6eaf80f62c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag : string ##### topic score : 0.1683335304260254 ##### individual score : 0.4313419759273529\n",
            "tag : types ##### topic score : 0.1683335304260254 ##### individual score : 0.30193570256233215\n",
            "tag : attributes ##### topic score : 0.168333500623703 ##### individual score : 0.1348075121641159\n",
            "tag : python ##### topic score : 0.16833336651325226 ##### individual score : 0.3098738193511963\n",
            "tag : html ##### topic score : 0.16833336651325226 ##### individual score : 0.10073015838861465\n",
            "tag : key ##### topic score : 0.16833306849002838 ##### individual score : 0.2191891372203827\n",
            "tag : updates ##### topic score : 0.16833306849002838 ##### individual score : 0.16892598569393158\n",
            "tag : implementation ##### topic score : 0.16833259165287018 ##### individual score : 0.22439436614513397\n",
            "tag : size ##### topic score : 0.16833259165287018 ##### individual score : 0.16774149239063263\n",
            "tag : display ##### topic score : 0.16833259165287018 ##### individual score : 0.1414836049079895\n",
            "tag proposals = ['html' 'attributes' 'display' 'size' 'updates']\n"
          ]
        }
      ],
      "source": [
        "test_str = 'How can i display keys and values of string python dict?'\n",
        "proposed_tags, ps = lda_tag_suggestion(input_string = test_str, lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = True)\n",
        "print('tag proposals = {}'.format(proposed_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xeEt5OTQqbS"
      },
      "source": [
        "Now we check what happens with a Title from the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKyJnMGBQw9v",
        "outputId": "ac042a11-7e80-4e76-8c12-57fcdc233046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******\n",
            "title: Is it okay to sign two different applications with the same key?\n",
            "saple tags: ['android']\n",
            "tag proposals = ['eclipse' 'fixed' 'updates' 'project' 'arrays']\n",
            "*******\n",
            "title: Cross platform IPC\n",
            "saple tags: ['cross-platform', 'ipc']\n",
            "tag proposals = ['express' 'iphone' 'hide' 'default' 'equivalent']\n"
          ]
        }
      ],
      "source": [
        "# sample text\n",
        "for _ in range(2):\n",
        "  print('*******')\n",
        "  idx = np.random.randint(len(df.Tags))\n",
        "  title_text = df.Title.to_list()[idx]\n",
        "\n",
        "  print('title: {}'.format(title_text))\n",
        "  print('saple tags:', df.Tags.to_list()[idx])\n",
        "\n",
        "  proposed_tags, _ = lda_tag_suggestion(input_string = title_text,  lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = False)\n",
        "  print('tag proposals = {}'.format(proposed_tags))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffekoqlhDJEi"
      },
      "source": [
        "And now from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNJIk36QDLEV",
        "outputId": "060e2721-fc44-48c1-d50f-10fabf1964ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******\n",
            "title: Are there alternate implementations of GNU getline interface?\n",
            "saple tags: ['c', 'licensing', 'getline']\n",
            "tag proposals = ['alternate' 'assembly' 'display' 'import' 'interface']\n",
            "*******\n",
            "title: Remove HTML5 notification permissions\n",
            "saple tags: ['javascript', 'html', 'html5-notifications']\n",
            "tag proposals = ['request' 'exception' 'animation' 'removable' 'wcf']\n"
          ]
        }
      ],
      "source": [
        "# sample text\n",
        "for _ in range(2):\n",
        "  print('*******')\n",
        "  idx = np.random.randint(len(test.Tags))\n",
        "  title_text = test.Title.to_list()[idx]\n",
        "\n",
        "  print('title: {}'.format(title_text))\n",
        "  print('saple tags:', test.Tags.to_list()[idx])\n",
        "\n",
        "  proposed_tags, _ = lda_tag_suggestion(input_string = title_text,  lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = False)\n",
        "  print('tag proposals = {}'.format(proposed_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dt65CssZsEc"
      },
      "source": [
        "Print of processing pipeline + prediction + gt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiHFQO_ba0Dg"
      },
      "source": [
        "## 3.5 Model evaluation\n",
        "\n",
        "We consider for a tag $i$:\n",
        "\n",
        "*   $TP_i$: The sum of the total number of correct predictions for the tag\n",
        "*   $FP_i$: The sum of the total number of bad predictions for the tag\n",
        "*   $TN_i$: All of the correctly non guessed tags are true negatives.\n",
        "*   $FN_i$: We do not predict negatives such that this number is zero.\n",
        "\n",
        "The first metric that would serve as an evaluation given the relevant parameters for the model the average F1-score for all tags.\n",
        "\n",
        "However, since each tag is unequaly represented on the dataset (as seen on the exploratory analysis), we need to ponder this by the presence of each tag on the dataset.\n",
        "\n",
        "The best suited evaluation metric for this problem is thus the micro-F1 score.\n",
        "\n",
        "Micro F1-score (short for micro-averaged F1 score) is used to assess the quality of multi-label binary problems.\n",
        "It measures the F1-score of the aggregated contributions of all classes.\n",
        "\n",
        "It corresponds to pondering the average of each class prediction by it's appearence.\n",
        "\n",
        "\n",
        "We define then\n",
        "\n",
        "*   $TP = \\sum_{\\forall i} TP_i$\n",
        "*   $FP = \\sum_{\\forall i} FN_i$\n",
        "*   $N = $  Total number of tags\n",
        "\n",
        "This quantities can be calculated without calculating the total ammount of\n",
        "\n",
        "*   $Pr_{micro} = \\frac{TP}{TP + FP}$\n",
        "*   $Re_{micro}= \\frac{TP}{N} = accuracy$\n",
        "\n",
        "As a bonus, this formulation allows us to efficiently calculate the values without calculating $TP_i$ and $FP_i$ for each class!\n",
        "\n",
        "And we use $F1_{micro} = 2\\frac{Pr_{micro}*Re_{micro}}{Pr_{micro}+Re_{micro}}$ as our evaluation metric.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4pyfSybaxbO"
      },
      "outputs": [],
      "source": [
        "# returns number of elements present in two lists\n",
        "def count_matches(str_list_1, str_list_2):\n",
        "  count = 0\n",
        "  for word in str_list_1:\n",
        "    if word in str_list_2:\n",
        "      count+= 1\n",
        "  return count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfWYl7hBb3HH"
      },
      "source": [
        "Now we check what happens with a Title from the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-3-W2U21MW8",
        "outputId": "316d0ee6-2116-46b6-bd8f-5a5cf9b85bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 0 out of 77109 questions...\n",
            "processed 7710 out of 77109 questions...\n",
            "processed 15420 out of 77109 questions...\n",
            "processed 23130 out of 77109 questions...\n",
            "processed 30840 out of 77109 questions...\n",
            "processed 38550 out of 77109 questions...\n",
            "processed 46260 out of 77109 questions...\n",
            "processed 53970 out of 77109 questions...\n",
            "processed 61680 out of 77109 questions...\n",
            "processed 69390 out of 77109 questions...\n",
            "processed 77100 out of 77109 questions...\n",
            "Positives = 233740\n",
            "micro TP = 18999\n",
            "micro FP = 51\n",
            "accuracy = 0.08128262171643706\n",
            "micro precision = 0.9973228346456693\n",
            "micro recall = 0.08128262171643706\n",
            "micro f1 = 0.07515724514419082\n"
          ]
        }
      ],
      "source": [
        "# calculate accuracy, recall, precision, TP, FP\n",
        "total = 0\n",
        "TP = 0\n",
        "FP = 0\n",
        "n_samples = len(df.Tags)\n",
        "idxs = np.random.randint(len(df.Tags),size = n_samples)\n",
        "\n",
        "for i, idx in enumerate(idxs):\n",
        "  title_text = df.Title.to_list()[idx]\n",
        "  gt_tags = df.Tags.to_list()[idx]\n",
        "  proposed_tags, _ = lda_tag_suggestion(input_string = title_text,  lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = False)\n",
        "  gt_pos = len(gt_tags)\n",
        "  pred_pos = len(proposed_tags)\n",
        "  positives = count_matches(proposed_tags, gt_tags)\n",
        "  total += gt_pos\n",
        "  TP += positives\n",
        "  # FP is given by the excedent of proposals.\n",
        "  FP += max(pred_pos - TP, 0)\n",
        "  if True:\n",
        "    if i % int(n_samples/10) == 0:\n",
        "      print('processed {} out of {} questions...'.format(i, n_samples))\n",
        "acc = TP/total\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP/(total)\n",
        "f1 = precision*recall/(precision+recall)\n",
        "print('Positives = {}'.format(total))\n",
        "print('micro TP = {}'.format(TP))\n",
        "print('micro FP = {}'.format(FP))\n",
        "print('accuracy = {}'.format(acc))\n",
        "print('micro precision = {}'.format(precision))\n",
        "print('micro recall = {}'.format(recall))\n",
        "print('micro f1 = {}'.format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5SqLOGtDrAp"
      },
      "source": [
        "And now from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiekkBsUb3HI",
        "outputId": "7e7bfba3-956a-4964-9f5a-6105093e9a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 0 out of 19278 questions...\n",
            "processed 1927 out of 19278 questions...\n",
            "processed 3854 out of 19278 questions...\n",
            "processed 5781 out of 19278 questions...\n",
            "processed 7708 out of 19278 questions...\n",
            "processed 9635 out of 19278 questions...\n",
            "processed 11562 out of 19278 questions...\n",
            "processed 13489 out of 19278 questions...\n",
            "processed 15416 out of 19278 questions...\n",
            "processed 17343 out of 19278 questions...\n",
            "processed 19270 out of 19278 questions...\n",
            "Positives = 57894\n",
            "micro TP = 4845\n",
            "micro FP = 13\n",
            "accuracy = 0.08368742874909317\n",
            "micro precision = 0.9973240016467683\n",
            "micro recall = 0.08368742874909317\n",
            "micro f1 = 0.07720869454360021\n"
          ]
        }
      ],
      "source": [
        "# calculate accuracy, recall, precision, TP, FP\n",
        "total = 0\n",
        "TP = 0\n",
        "FP = 0\n",
        "n_samples = len(test.Tags)\n",
        "idxs = np.random.randint(len(test.Tags),size = n_samples)\n",
        "for i, idx in enumerate(idxs):\n",
        "  title_text = test.Title.to_list()[idx]\n",
        "  gt_tags = test.Tags.to_list()[idx]\n",
        "  proposed_tags, _ = lda_tag_suggestion(input_string = title_text,  lda_model = title_lda_model, corpus_dictionary = title_dictionary,\n",
        "                                   token2tag_dict = token2tag_dict, verbose = False)\n",
        "  gt_pos = len(gt_tags)\n",
        "  pred_pos = len(proposed_tags)\n",
        "  positives = count_matches(proposed_tags, gt_tags)\n",
        "  total += gt_pos\n",
        "  TP += positives\n",
        "  # FP is given by the excedent of proposals.\n",
        "  FP += max(pred_pos - TP, 0)\n",
        "  if True:\n",
        "    if i % int(n_samples/10) == 0:\n",
        "      print('processed {} out of {} questions...'.format(i, n_samples))\n",
        "acc = TP/total\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP/(total)\n",
        "f1 = precision*recall/(precision+recall)\n",
        "print('Positives = {}'.format(total))\n",
        "print('micro TP = {}'.format(TP))\n",
        "print('micro FP = {}'.format(FP))\n",
        "print('accuracy = {}'.format(acc))\n",
        "print('micro precision = {}'.format(precision))\n",
        "print('micro recall = {}'.format(recall))\n",
        "print('micro f1 = {}'.format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Unsupervised learning on titles"
      ],
      "metadata": {
        "id": "rxWwlmNbp79k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r1W0Mc0A1wC"
      },
      "source": [
        "## 4.1 Body Pre-processing\n",
        "\n",
        "Here we process the body of questions into a bow representation. Applying the same pipeline that we used for the Title is not straightforward since the text contains different sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX7wTtQBA1wD",
        "outputId": "45468671-0e60-422d-941c-3aeeb78e4082"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<p>I was going thru some single page website examples and found  this: <a href=\"http://alwayscreative.net/\" rel=\"noreferrer\">http://alwayscreative.net/</a>. I am totally amazed by the disc in the background that rotates infinitely. i have looked at some examples but none worked that way. Can anyone tell me how was that implemented.\\nThanks.</p>\\n',\n",
              " '<p>Does anybody know why this error happens on Xcode 5?</p>\\n<p><img src=\"https://i.stack.imgur.com/uBCcr.png\" alt=\"error\" /></p>\\n<p><strong>Answer</strong></p>\\n<p>I had this problem when I accidentally renamed a .psd as a .png. Converting the image to an actual png instead of a Photoshop file fixed it for me.</p>\\n',\n",
              " '<p>I\\'m using guice for dependency injection with aop from <a href=\"http://aopalliance.sourceforge.net/\" rel=\"noreferrer\">aopalliance</a>. I can\\'t quite figure out what\\'s aopalliance all about and who implemented the version (dated from 2004) that\\'s on their sourceforge page. Why is guice using this version instead of a more known package such as AspectJ?</p>\\n\\n<p>Also, do you know of any tutorials on the aopalliance version?</p>\\n\\n<p>Thanks</p>\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "df.Body.to_list()[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_nO8nBBA1wF"
      },
      "outputs": [],
      "source": [
        "processed_Bodies = df.Body.map(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cltXuTMGA1wF",
        "outputId": "028ddc57-30b3-45df-94d0-7df2d59297b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67997    [pi, go, singl, page, websit, exampl, hrefhttp...\n",
              "76486    [pdoe, anybodi, know, error, happen, xcode, 5p...\n",
              "29308    [pim, guic, depend, inject, aop, hrefhttpaopal...\n",
              "83844    [pi, follow, 500, server, error, publish, azur...\n",
              "82803    [pi, get, troubl, rail, project（redmine23, rai...\n",
              "48827    [pi, tri, implement, hrefhttpenwikipediaorgwik...\n",
              "30263    [pif, destructor, explicitli, myobjectobject, ...\n",
              "52564    [pi, need, hrefhttpmsdnmicrosoftcomen-uslibrar...\n",
              "39947    [pi, tri, write, add-in, visual, studio, thing...\n",
              "83261    [pto, protect, user, maliciuo, applet, want, d...\n",
              "Name: Body, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "processed_Bodies[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBdQRqSBA1wF",
        "outputId": "63d5b62d-7698-44ed-a052-c53b37dfa482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 amaz\n",
            "1 background\n",
            "2 disc\n",
            "3 exampl\n",
            "4 go\n",
            "5 hrefhttpalwayscreativenet\n",
            "6 implement\n",
            "7 infinit\n",
            "8 look\n",
            "9 page\n",
            "10 pi\n"
          ]
        }
      ],
      "source": [
        "body_dictionary = gensim.corpora.Dictionary(processed_Bodies)\n",
        "count = 0\n",
        "for k, v in body_dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF9BUKxzA1wG"
      },
      "outputs": [],
      "source": [
        "body_dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ya5YzVA1wG"
      },
      "outputs": [],
      "source": [
        "body_bow_corpus = [body_dictionary.doc2bow(body) for body in processed_Bodies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtlHbFzxA1wG"
      },
      "outputs": [],
      "source": [
        "def body_sample_nlp_pipeline(sample_idx):\n",
        "  print('sample idx:', sample_idx)\n",
        "\n",
        "  print('saple tags:', df.Tags.to_list()[sample_idx])\n",
        "  print('\\nprocessing pipeline: \\n')\n",
        "  print('sample body:', df.Title.to_list()[sample_idx])\n",
        "  print('preprocessed title:', processed_Bodies[sample_idx])\n",
        "  print('bow_corpus of body:', body_bow_corpus[sample_idx])\n",
        "  print('bag of words equivalence: \\n')\n",
        "  bow_doc_sample = body_bow_corpus[sample_idx]\n",
        "  for i in range(len(bow_doc_sample)):\n",
        "      print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_sample[i][0],\n",
        "                                                body_dictionary[bow_doc_sample[i][0]], bow_doc_sample[i][1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTLMtP3dA1wH",
        "outputId": "b80e7ab6-8d70-4769-be1e-d5dbc18fcc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample idx: 1\n",
            "saple tags: ['ios', 'iphone', 'xcode', 'ios7', 'xcode5']\n",
            "\n",
            "processing pipeline: \n",
            "\n",
            "sample body: Xcode error : Distill failed for unknown reasons\n",
            "preprocessed title: ['pwhere', 'list', 'mime', 'type', 'identifi', 'charact', 'strongmicrosoft', 'offic', '2007strong', 'filesp', 'pi', 'upload', 'form', 'restrict', 'upload', 'base', 'extens', 'identifi', 'charact', 'strongoffic', '2007', 'mimestrong', 'typesp', 'pcan', 'helpp']\n",
            "bow_corpus of body: [(17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1)]\n",
            "bag of words equivalence: \n",
            "\n",
            "Word 17 (\"5p\") appears 1 time.\n",
            "Word 18 (\"accident\") appears 1 time.\n",
            "Word 19 (\"actual\") appears 1 time.\n",
            "Word 20 (\"alterror\") appears 1 time.\n",
            "Word 21 (\"anybodi\") appears 1 time.\n",
            "Word 22 (\"convert\") appears 1 time.\n",
            "Word 23 (\"error\") appears 1 time.\n",
            "Word 24 (\"file\") appears 1 time.\n",
            "Word 25 (\"fix\") appears 1 time.\n",
            "Word 26 (\"happen\") appears 1 time.\n",
            "Word 27 (\"imag\") appears 1 time.\n",
            "Word 28 (\"instead\") appears 1 time.\n",
            "Word 29 (\"know\") appears 1 time.\n",
            "Word 30 (\"mep\") appears 1 time.\n",
            "Word 31 (\"p\") appears 1 time.\n",
            "Word 32 (\"pdoe\") appears 1 time.\n",
            "Word 33 (\"photoshop\") appears 1 time.\n",
            "Word 34 (\"pimg\") appears 1 time.\n",
            "Word 35 (\"png\") appears 2 time.\n",
            "Word 36 (\"problem\") appears 1 time.\n",
            "Word 37 (\"renam\") appears 1 time.\n",
            "Word 38 (\"xcode\") appears 1 time.\n"
          ]
        }
      ],
      "source": [
        "body_sample_nlp_pipeline(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwtE7qNlA1wH"
      },
      "source": [
        "### Question: How many topics should we use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nTVoyC5A1wH"
      },
      "outputs": [],
      "source": [
        "body_lda_model = gensim.models.LdaMulticore(body_bow_corpus, num_topics=20, id2word=body_dictionary, passes=20, workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9z1TsLMy4b2"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model_file_path = \"/content/drive/MyDrive/Colab Notebooks/Lda models/body_lda_model\"\n",
        "body_lda_model.save(model_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGZiT1SGA1wI",
        "outputId": "02085437-d18d-4b00-b18b-434eab55715f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.024*\"page\" + 0.016*\"want\" + 0.015*\"control\" + 0.015*\"like\" + 0.013*\"work\" + 0.013*\"form\" + 0.013*\"way\" + 0.013*\"user\" + 0.011*\"text\" + 0.011*\"p\"\n",
            "Topic: 1 \n",
            "Words: 0.037*\"user\" + 0.026*\"request\" + 0.019*\"servic\" + 0.017*\"url\" + 0.016*\"server\" + 0.015*\"send\" + 0.014*\"client\" + 0.012*\"http\" + 0.012*\"respons\" + 0.012*\"log\"\n",
            "Topic: 2 \n",
            "Words: 0.040*\"tabl\" + 0.023*\"queri\" + 0.023*\"column\" + 0.022*\"data\" + 0.020*\"id\" + 0.019*\"select\" + 0.019*\"databas\" + 0.018*\"row\" + 0.018*\"sql\" + 0.012*\"p\"\n",
            "Topic: 3 \n",
            "Words: 0.104*\"file\" + 0.021*\"project\" + 0.019*\"instal\" + 0.017*\"build\" + 0.016*\"directori\" + 0.014*\"path\" + 0.013*\"version\" + 0.013*\"packag\" + 0.012*\"folder\" + 0.011*\"creat\"\n",
            "Topic: 4 \n",
            "Words: 0.672*\"--\" + 0.048*\"-\" + 0.029*\"+\" + 0.023*\"info\" + 0.015*\"-+\" + 0.010*\"null\" + 0.010*\"1\" + 0.009*\"ltdependencygt\" + 0.006*\"ltoption\" + 0.004*\"ltplugingt\"\n",
            "Topic: 5 \n",
            "Words: 0.022*\"div\" + 0.022*\"git\" + 0.021*\"ltdivgt\" + 0.021*\"ltdiv\" + 0.018*\"width\" + 0.017*\"branch\" + 0.015*\"color\" + 0.014*\"commit\" + 0.012*\"height\" + 0.012*\"chang\"\n",
            "Topic: 6 \n",
            "Words: 0.350*\"#\" + 0.041*\"end\" + 0.036*\"def\" + 0.028*\"import\" + 0.025*\"precod\" + 0.025*\"includ\" + 0.015*\"rail\" + 0.014*\"model\" + 0.013*\"defin\" + 0.010*\"django\"\n",
            "Topic: 7 \n",
            "Words: 0.078*\"ul\" + 0.040*\"ol\" + 0.019*\"lia\" + 0.018*\"li\" + 0.017*\"data\" + 0.014*\"-\" + 0.013*\"databas\" + 0.013*\"relnofollow\" + 0.011*\"use\" + 0.010*\"object\"\n",
            "Topic: 8 \n",
            "Words: 0.072*\"function\" + 0.050*\"var\" + 0.047*\"return\" + 0.028*\"true\" + 0.020*\"fals\" + 0.019*\"+\" + 0.018*\"code\" + 0.015*\"event\" + 0.012*\"new\" + 0.012*\"call\"\n",
            "Topic: 9 \n",
            "Words: 0.018*\"use\" + 0.016*\"im\" + 0.015*\"like\" + 0.013*\"code\" + 0.011*\"know\" + 0.011*\"p\" + 0.009*\"look\" + 0.009*\"question\" + 0.008*\"way\" + 0.008*\"work\"\n",
            "Topic: 10 \n",
            "Words: 0.060*\"1\" + 0.055*\"0\" + 0.036*\"2\" + 0.034*\"+\" + 0.026*\"3\" + 0.026*\"int\" + 0.021*\"x\" + 0.021*\"b\" + 0.017*\"4\" + 0.017*\"c\"\n",
            "Topic: 11 \n",
            "Words: 0.064*\"class\" + 0.049*\"public\" + 0.036*\"new\" + 0.027*\"method\" + 0.025*\"return\" + 0.024*\"void\" + 0.023*\"string\" + 0.022*\"object\" + 0.018*\"privat\" + 0.018*\"static\"\n",
            "Topic: 12 \n",
            "Words: 0.103*\"error\" + 0.077*\"blockquot\" + 0.030*\"tri\" + 0.024*\"p\" + 0.023*\"follow\" + 0.021*\"except\" + 0.018*\"type\" + 0.018*\"code\" + 0.018*\"fail\" + 0.018*\"warn\"\n",
            "Topic: 13 \n",
            "Words: 0.056*\"app\" + 0.029*\"date\" + 0.025*\"time\" + 0.021*\"android\" + 0.016*\"devic\" + 0.014*\"day\" + 0.013*\"io\" + 0.011*\"iphon\" + 0.011*\"p\" + 0.010*\"googl\"\n",
            "Topic: 14 \n",
            "Words: 0.026*\"valu\" + 0.026*\"string\" + 0.020*\"like\" + 0.019*\"way\" + 0.018*\"list\" + 0.016*\"array\" + 0.016*\"want\" + 0.015*\"p\" + 0.013*\"number\" + 0.010*\"thisp\"\n",
            "Topic: 15 \n",
            "Words: 0.057*\"test\" + 0.048*\"line\" + 0.029*\"file\" + 0.029*\"script\" + 0.026*\"command\" + 0.025*\"run\" + 0.018*\"like\" + 0.018*\"python\" + 0.017*\"output\" + 0.015*\"want\"\n",
            "Topic: 16 \n",
            "Words: 0.023*\"thread\" + 0.021*\"process\" + 0.020*\"memori\" + 0.019*\"run\" + 0.018*\"time\" + 0.010*\"byte\" + 0.010*\"task\" + 0.009*\"program\" + 0.009*\"data\" + 0.009*\"read\"\n",
            "Topic: 17 \n",
            "Words: 0.026*\"server\" + 0.022*\"applic\" + 0.020*\"connect\" + 0.018*\"window\" + 0.017*\"run\" + 0.015*\"studio\" + 0.014*\"visual\" + 0.013*\"work\" + 0.012*\"set\" + 0.011*\"develop\"\n",
            "Topic: 18 \n",
            "Words: 0.250*\"gt\" + 0.047*\"import\" + 0.029*\"lt\" + 0.026*\"compon\" + 0.025*\"’\" + 0.019*\"templat\" + 0.016*\"const\" + 0.010*\"react\" + 0.010*\"default\" + 0.009*\"export\"\n",
            "Topic: 19 \n",
            "Words: 0.073*\"imag\" + 0.026*\"descript\" + 0.019*\"view\" + 0.018*\"altent\" + 0.016*\"pa\" + 0.013*\"pimg\" + 0.012*\"relnoreferrerimg\" + 0.011*\"p\" + 0.010*\"activ\" + 0.009*\"anim\"\n"
          ]
        }
      ],
      "source": [
        "for idx, topic in body_lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93WNb1ZSA1wL"
      },
      "outputs": [],
      "source": [
        "def infer_body_topic_score(sample_idx, ):\n",
        "  for index, score in sorted(body_lda_model[body_bow_corpus[sample_idx]], key=lambda tup: -1*tup[1]):\n",
        "      print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, body_lda_model.print_topic(index, 10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbYsrKKOA1wM",
        "outputId": "8f60bccc-9ff1-4a2d-9c65-aed87a75edbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample idx: 11010\n",
            "saple tags: ['html', 'css', 'forms']\n",
            "\n",
            "processing pipeline: \n",
            "\n",
            "sample body: Why use definition lists (DL,DD,DT) tags for HTML forms instead of tables?\n",
            "preprocessed title: ['pwhat', 'prefer', 'way', 'set', 'html', 'titl', 'head', 'view', 'master', 'pagesp', 'pone', 'way', 'pagetitl', 'aspx', 'file', 'requir', 'master', 'page', 'mess', 'html', 'code', 'let', 'assum', 'server', 'control', 'pure', 'html', 'better', 'idea', 'p', 'pupdat', 'like', 'set', 'titl', 'view', 'control', 'modelp']\n",
            "bow_corpus of body: [(3, 1), (311, 1), (318, 1), (388, 1), (406, 1), (431, 1), (478, 1), (668, 1), (677, 1), (732, 1), (776, 2), (1449, 1), (5361, 1), (5441, 1)]\n",
            "bag of words equivalence: \n",
            "\n",
            "Word 3 (\"exampl\") appears 1 time.\n",
            "Word 311 (\"recent\") appears 1 time.\n",
            "Word 318 (\"thing\") appears 1 time.\n",
            "Word 388 (\"come\") appears 1 time.\n",
            "Word 406 (\"form\") appears 1 time.\n",
            "Word 431 (\"pfor\") appears 1 time.\n",
            "Word 478 (\"likep\") appears 1 time.\n",
            "Word 668 (\"advantag\") appears 1 time.\n",
            "Word 677 (\"pive\") appears 1 time.\n",
            "Word 732 (\"html\") appears 1 time.\n",
            "Word 776 (\"typetext\") appears 2 time.\n",
            "Word 1449 (\"pre\") appears 1 time.\n",
            "Word 5361 (\"tablesp\") appears 1 time.\n",
            "Word 5441 (\"classlang-html\") appears 1 time.\n",
            "\n",
            "#####\n",
            "prediction:\n",
            "\n",
            "\n",
            "Score: 0.3699597716331482\t \n",
            "Topic: 0.018*\"use\" + 0.016*\"im\" + 0.015*\"like\" + 0.013*\"code\" + 0.011*\"know\" + 0.011*\"p\" + 0.009*\"look\" + 0.009*\"question\" + 0.008*\"way\" + 0.008*\"work\"\n",
            "\n",
            "Score: 0.3008294105529785\t \n",
            "Topic: 0.022*\"div\" + 0.022*\"git\" + 0.021*\"ltdivgt\" + 0.021*\"ltdiv\" + 0.018*\"width\" + 0.017*\"branch\" + 0.015*\"color\" + 0.014*\"commit\" + 0.012*\"height\" + 0.012*\"chang\"\n",
            "\n",
            "Score: 0.18976327776908875\t \n",
            "Topic: 0.024*\"page\" + 0.016*\"want\" + 0.015*\"control\" + 0.015*\"like\" + 0.013*\"work\" + 0.013*\"form\" + 0.013*\"way\" + 0.013*\"user\" + 0.011*\"text\" + 0.011*\"p\"\n",
            "\n",
            "Score: 0.08943050354719162\t \n",
            "Topic: 0.040*\"tabl\" + 0.023*\"queri\" + 0.023*\"column\" + 0.022*\"data\" + 0.020*\"id\" + 0.019*\"select\" + 0.019*\"databas\" + 0.018*\"row\" + 0.018*\"sql\" + 0.012*\"p\"\n"
          ]
        }
      ],
      "source": [
        "idx = 11010\n",
        "body_sample_nlp_pipeline(idx)\n",
        "print(\"\\n#####\\nprediction:\\n\")\n",
        "infer_body_topic_score(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4qOLxJlA1wM",
        "outputId": "46fcac55-c7a4-468e-abe5-998721600f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.050\t Topcic: 0.024*\"page\" + 0.016*\"want\" + 0.015*\"control\" + 0.015*\"like\" + 0.013*\"work\"\n",
            "Score: 0.050\t Topcic: 0.037*\"user\" + 0.026*\"request\" + 0.019*\"servic\" + 0.017*\"url\" + 0.016*\"server\"\n",
            "Score: 0.050\t Topcic: 0.040*\"tabl\" + 0.023*\"queri\" + 0.023*\"column\" + 0.022*\"data\" + 0.020*\"id\"\n",
            "Score: 0.050\t Topcic: 0.104*\"file\" + 0.021*\"project\" + 0.019*\"instal\" + 0.017*\"build\" + 0.016*\"directori\"\n",
            "Score: 0.050\t Topcic: 0.672*\"--\" + 0.048*\"-\" + 0.029*\"+\" + 0.023*\"info\" + 0.015*\"-+\"\n",
            "Score: 0.050\t Topcic: 0.022*\"div\" + 0.022*\"git\" + 0.021*\"ltdivgt\" + 0.021*\"ltdiv\" + 0.018*\"width\"\n",
            "Score: 0.050\t Topcic: 0.350*\"#\" + 0.041*\"end\" + 0.036*\"def\" + 0.028*\"import\" + 0.025*\"precod\"\n",
            "Score: 0.050\t Topcic: 0.078*\"ul\" + 0.040*\"ol\" + 0.019*\"lia\" + 0.018*\"li\" + 0.017*\"data\"\n",
            "Score: 0.050\t Topcic: 0.072*\"function\" + 0.050*\"var\" + 0.047*\"return\" + 0.028*\"true\" + 0.020*\"fals\"\n",
            "Score: 0.050\t Topcic: 0.018*\"use\" + 0.016*\"im\" + 0.015*\"like\" + 0.013*\"code\" + 0.011*\"know\"\n",
            "Score: 0.050\t Topcic: 0.060*\"1\" + 0.055*\"0\" + 0.036*\"2\" + 0.034*\"+\" + 0.026*\"3\"\n",
            "Score: 0.050\t Topcic: 0.064*\"class\" + 0.049*\"public\" + 0.036*\"new\" + 0.027*\"method\" + 0.025*\"return\"\n",
            "Score: 0.050\t Topcic: 0.103*\"error\" + 0.077*\"blockquot\" + 0.030*\"tri\" + 0.024*\"p\" + 0.023*\"follow\"\n",
            "Score: 0.050\t Topcic: 0.056*\"app\" + 0.029*\"date\" + 0.025*\"time\" + 0.021*\"android\" + 0.016*\"devic\"\n",
            "Score: 0.050\t Topcic: 0.026*\"valu\" + 0.026*\"string\" + 0.020*\"like\" + 0.019*\"way\" + 0.018*\"list\"\n",
            "Score: 0.050\t Topcic: 0.057*\"test\" + 0.048*\"line\" + 0.029*\"file\" + 0.029*\"script\" + 0.026*\"command\"\n",
            "Score: 0.050\t Topcic: 0.023*\"thread\" + 0.021*\"process\" + 0.020*\"memori\" + 0.019*\"run\" + 0.018*\"time\"\n",
            "Score: 0.050\t Topcic: 0.026*\"server\" + 0.022*\"applic\" + 0.020*\"connect\" + 0.018*\"window\" + 0.017*\"run\"\n",
            "Score: 0.050\t Topcic: 0.250*\"gt\" + 0.047*\"import\" + 0.029*\"lt\" + 0.026*\"compon\" + 0.025*\"’\"\n",
            "Score: 0.050\t Topcic: 0.073*\"imag\" + 0.026*\"descript\" + 0.019*\"view\" + 0.018*\"altent\" + 0.016*\"pa\"\n"
          ]
        }
      ],
      "source": [
        "# test on unseen data\n",
        "unseen_title = 'There seems to be an'\n",
        "bow_vector = body_dictionary.doc2bow(preprocess(unseen_title))\n",
        "for index, score in sorted(body_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {:.3f}\\t Topcic: {}\".format(score, body_lda_model.print_topic(index, 5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPUsocP-BL3a"
      },
      "source": [
        "## Tag from body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGfh1YgCBGJO"
      },
      "outputs": [],
      "source": [
        "# extract tag proposals from topics\n",
        "unseen_body = 'How can I declare a struct in java if there is a list of random integers that I can lorem ipsum'\n",
        "bow_vector = body_dictionary.doc2bow(preprocess(unseen_body))\n",
        "\n",
        "scores = []\n",
        "words = []\n",
        "for index, score in sorted(body_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    scores.append(score)\n",
        "    words.append(title_lda_model.get_topic_terms(index, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V52447GbBtA7",
        "outputId": "0af8e399-89eb-48fd-97f8-e504e63bbeff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.40980998),\n",
              " (305, 0.17781377),\n",
              " (77, 0.09306017),\n",
              " (269, 0.05579522),\n",
              " (143, 0.053933434)]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "words[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8E_zY0lBGJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296a24da-409f-414f-b934-1c0ca8ce051f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "background\n",
            "construct\n"
          ]
        }
      ],
      "source": [
        "# compare with dict of tags\n",
        "for bow_id, score in words[0]:\n",
        "  if body_dictionary[bow_id] in tags_array:\n",
        "    print(body_dictionary[bow_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLNqjgTgBGJP"
      },
      "outputs": [],
      "source": [
        "body_tag_score = []\n",
        "body_tag_proposal = []\n",
        "for index, topic_score in sorted(body_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    words = body_lda_model.get_topic_terms(index, 5)\n",
        "    # compare with dict of tags\n",
        "    for bow_id, score in words:\n",
        "      if body_dictionary[bow_id] in tags_array:\n",
        "        body_tag_proposal.append(body_dictionary[bow_id])\n",
        "        body_tag_score.append((topic_score, score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ5YQe_eBGJQ",
        "outputId": "f5db71c1-52e3-44f5-ebe5-7cba4ff90780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tag : string, topic score : 0.4822022318840027, individual score : 0.02608604170382023\n",
            "tag : list, topic score : 0.4822022318840027, individual score : 0.018192294985055923\n",
            "tag : git, topic score : 0.22808238863945007, individual score : 0.021855566650629044\n",
            "tag : width, topic score : 0.22808238863945007, individual score : 0.01755526103079319\n"
          ]
        }
      ],
      "source": [
        "for tag, score in zip(body_tag_proposal, body_tag_score):\n",
        "  print('tag : {}, topic score : {}, individual score : {}'.format(tag, score[0], score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_4w2zhGBGJQ"
      },
      "outputs": [],
      "source": [
        "# catch a tag given a threshold\n",
        "body_tag_thresh = 0.1\n",
        "for tag, score in zip(body_tag_proposal, body_tag_score):\n",
        "  if score[1] > body_tag_thresh:\n",
        "    print('tag : {} ##### topic score : {} ##### individual score : {}'.format(tag, score[0], score[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgzoJ89qnSB"
      },
      "source": [
        "# 5. Title + body to tags:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXQ50I4mEEgM"
      },
      "outputs": [],
      "source": [
        "def infer_title_tags(title_text, thr = 0.1):\n",
        "  # extract tag proposals from topics\n",
        "  bow_vector = title_dictionary.doc2bow(preprocess(title_text))\n",
        "\n",
        "  scores = []\n",
        "  words = []\n",
        "  for index, score in sorted(title_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "      scores.append(score)\n",
        "      words.append(title_lda_model.get_topic_terms(index, 5))\n",
        "\n",
        "  title_tag_score = []\n",
        "  title_tag_proposal = []\n",
        "  for index, topic_score in sorted(title_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "      words = title_lda_model.get_topic_terms(index, 5)\n",
        "      # compare with dict of tags\n",
        "      for bow_id, score in words:\n",
        "        if title_dictionary[bow_id] in tags_array:\n",
        "          title_tag_proposal.append(title_dictionary[bow_id])\n",
        "          title_tag_score.append((topic_score, score))\n",
        "  # catch a tag given a threshold\n",
        "  proposals = {}\n",
        "  for tag, score in zip(title_tag_proposal, title_tag_score):\n",
        "    if score[1] > thr:\n",
        "      #print('tag : {} ##### topic score : {} ##### individual score : {}'.format(tag, score[0], score[1]))\n",
        "      proposals[tag] = (score[0], score[1])\n",
        "  return proposals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3oNgPA2DXJm"
      },
      "outputs": [],
      "source": [
        "def infer_body_tags(body_text, thr = 0.1):\n",
        "  # extract tag proposals from topics\n",
        "  bow_vector = body_dictionary.doc2bow(preprocess(body_text))\n",
        "\n",
        "  scores = []\n",
        "  words = []\n",
        "  for index, score in sorted(body_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "      scores.append(score)\n",
        "      words.append(body_lda_model.get_topic_terms(index, 5))\n",
        "\n",
        "  body_tag_score = []\n",
        "  body_tag_proposal = []\n",
        "  for index, topic_score in sorted(body_lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "      words = body_lda_model.get_topic_terms(index, 5)\n",
        "      # compare with dict of tags\n",
        "      for bow_id, score in words:\n",
        "        if body_dictionary[bow_id] in tags_array:\n",
        "          body_tag_proposal.append(body_dictionary[bow_id])\n",
        "          body_tag_score.append((topic_score, score))\n",
        "  # catch a tag given a threshold\n",
        "  proposals = {}\n",
        "  for tag, score in zip(body_tag_proposal, body_tag_score):\n",
        "    if score[1] > thr:\n",
        "      #print('tag : {} ##### topic score : {} ##### individual score : {}'.format(tag, score[0], score[1]))\n",
        "      proposals[tag] = (score[0], score[1])\n",
        "  return proposals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm8nTqMWEhMD",
        "outputId": "1dabd896-38aa-47d2-b88f-659748342751"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'python': (0.12625113, 0.30987382),\n",
              " 'html': (0.12625113, 0.10073016),\n",
              " 'list': (0.12625109, 0.2860862),\n",
              " 'api': (0.12625109, 0.11448753),\n",
              " 'contain': (0.12625109, 0.11375814),\n",
              " 'group': (0.12625036, 0.1365088),\n",
              " 'block': (0.12625034, 0.17727534),\n",
              " 'email': (0.12625034, 0.115352795),\n",
              " 'default': (0.1262484, 0.15170397),\n",
              " 'express': (0.1262484, 0.118174724),\n",
              " 'android': (0.12624569, 0.60257727)}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "infer_title_tags('i want to know how to create a python dict given a list of words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyJmjA8nD6Am",
        "outputId": "904bf5db-4735-49c0-df53-1f54bb3a84ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "infer_body_tags('i want to know how to create a python dict given a list of words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sYrVKAccesG",
        "outputId": "d6ac16c6-0a22-438e-d42e-cd115b90d867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['android', 'python', 'list', 'block', 'default']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def infer_tag_proposals(title, body, thr=0.1, n_max=5):\n",
        "    def aggregate_tags(tag_dict, proposals, scores):\n",
        "        for tag, scores_tuple in tag_dict.items():\n",
        "            if tag in proposals:\n",
        "                idx = proposals.index(tag)\n",
        "                scores[idx] += sum(scores_tuple)\n",
        "            else:\n",
        "                proposals.append(tag)\n",
        "                scores.append(sum(scores_tuple))\n",
        "\n",
        "    # Get title and body tag proposals\n",
        "    title_tags = infer_title_tags(title, thr)\n",
        "    body_tags = infer_body_tags(body, thr)\n",
        "\n",
        "    # Aggregate tags and scores from title and body\n",
        "    proposals = []\n",
        "    scores = []\n",
        "\n",
        "    aggregate_tags(title_tags, proposals, scores)\n",
        "    aggregate_tags(body_tags, proposals, scores)\n",
        "\n",
        "    # Sort proposals based on scores\n",
        "    sorted_indices = np.argsort([-score for score in scores])\n",
        "    sorted_proposals = [proposals[idx] for idx in sorted_indices]\n",
        "\n",
        "    # Return only up to n_max proposals\n",
        "    return sorted_proposals[:n_max]\n",
        "\n",
        "# Example usage:\n",
        "title = 'i want to know how to create a python dict given a list of words'\n",
        "body = title\n",
        "infer_tag_proposals(title, body, thr=0.1, n_max=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWXM1--VJvry",
        "outputId": "fa1e8961-120b-4f42-9854-623402c3a38d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['android', 'python', 'list', 'block', 'default']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "test1 = \"i want to know how to create a python dict given a list of words\"\n",
        "infer_tag_proposals(test1, test1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}